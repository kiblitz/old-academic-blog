[{"content":" Drag the points!\nIntroduction Given a set of points, what is the smallest convex shape that encloses all of them? What is the boundary of this shape?\nThis is the convex hull problem.\n2D Convex Hull Observations Notice that given a convex hull, all points lie on the same side of every edge.\nObserve that for every edge, all points lie on the same side (right for top and bottom; left for all other).\nIdea 1: Add Edges with All Points on the same side Naive Algorithm $$ \\begin{align*} \u0026amp;\\texttt{bool allPointsOnSameSideOf($e$):}\\newline \u0026amp;\\texttt{\\qquad for all other points $p\\not\\in e$:}\\newline \u0026amp;\\texttt{\\qquad \\qquad if any $p$ on different side of $e$:}\\newline \u0026amp;\\texttt{\\qquad \\qquad \\qquad return false}\\newline \u0026amp;\\texttt{\\qquad return true}\\newline \u0026amp;\\newline \u0026amp;\\texttt{for all points $p1$:}\\newline \u0026amp;\\texttt{\\qquad for all other points $p2$:}\\newline \u0026amp;\\texttt{\\qquad \\qquad consider edge $e$ = ($p1$, $p2$)}\\newline \u0026amp;\\texttt{\\qquad \\qquad if allPointsOnSameSideOf($e$):}\\newline \u0026amp;\\texttt{\\qquad \\qquad \\qquad add $e$ to convex hull}\\newline \\end{align*} $$\nChecking if all points are on the same side is a linear ($\\mathcal{O}(n)$) operation. Iterating through all possible edges is a quadratic operation ($\\mathcal{O}(n^2)$). Thus, this algorithm has cubic time complexity ($\\mathcal{O}(n^3)$).\nObservation We are checking all possible edges, but really edges are contiguous on a hull ($A\\rightarrow B\\rightarrow C\\rightarrow A$ like a chain).\nBut what about the first edge? Here\u0026rsquo;s another observation: the convex hull must contain the leftmost ($\\min_x$) point!\nIf there are multiple leftmost points, then they must all be on the convex hull. Otherwise, that point would not be contained in the convex hull.\nWith this chain in mind, we shouldn\u0026rsquo;t be iterating over all points for the next: in a chain, the next point should be \u0026ldquo;close\u0026rdquo; to the current pivot point. Could we precompute with a sort in some way?\nGraham Scan Algorithm $$ \\begin{align*} \u0026amp;\\texttt{let hull = [$\\min_x$]}\\newline \u0026amp;\\texttt{sort all points by $\\theta$ with $\\min_x$}\\newline \u0026amp;\\newline \u0026amp;\\texttt{for all points $p\\neq\\min_x$:}\\newline \u0026amp;\\texttt{\\qquad add $p$ to hull}\\newline \u0026amp;\\texttt{\\qquad while hull (with $p$) is no longer convex:}\\newline \u0026amp;\\texttt{\\qquad \\qquad pop hull}\\newline \\end{align*} $$ Convex meaning that the hull only \u0026ldquo;leans\u0026rdquo; in one direction (always curving left OR always curving right). This can easily be checked by verifying that the current point $p$ is on the same side of the previous edge (or vacuously true if there is no previous edge).\nExample Here, the leftmost point is highlighted in red. We sort the other points by their angle with this point (ordered numbering).\nAfter a few iterations, our hull is still convex (always left leaning).\nNow, the hull\u0026rsquo;s convexitivity breaks.\nStill broken (we only have to check that the current red point is on the left side of the 2nd-to-last edge).\nConvex!\nIf we continue the algorithm, we will eventually reach the full convex hull.\nAnalysis Determining the leftmost point just requires a linear scan ($\\mathcal{O}(n)$). Since determining the angle between two points takes constant time ($\\mathcal{O}(1)$), the initial sort has the normal time complexity $\\mathcal{O}(n \\log n)$.\nEvery point will be the current point (red dot in example) exactly once, so this iteration has linear time complexity ($\\mathcal{O}(n)$).\nWhat about popping non-convex points? Observe that any point can be popped at most once! So it has linear time complexity ($\\mathcal{O}(n)$).\n$$\\mathcal{O}(n) + \\mathcal{O}(n \\log n) + \\mathcal{O}(n) + \\mathcal{O}(n)$$ $$\\subseteq\\mathcal{O}(n \\log n)$$\nA bit of notation abuse, but I think the point still gets across.\nAbove and Beyond Anything in this section serves as very light introductions to convex hull extensions. You should treat them as just introductions and feel free to explore further beyond this blog post.\nThere are various algorithms for solving this problem in $d$-dimensions. For the 3D problem, there exists a deterministic divide-and-conquer $\\mathcal{O}(n \\log n)$ algorithm (but is notoriously difficult, especially the merge step).\nChan\u0026rsquo;s Algorithm Chan\u0026rsquo;s algorithm is an output-sensitive algorithm for calculating the convex hull in 2D and 3D space.\nIt relies on existing $\\mathcal{O}(n \\log n)$ algorithms in those spaces (Graham Scan, divide-and-conquer, etc.) and uses them to solve subpartitions of the original point set. It then combines these mini-convex hulls to solve the full problem.\nIt has time complexity $\\mathcal{O}(n \\log h)$, where $h$ is the number of vertices in the solution convex hull.\nQuick Hull For the general $d$, Quick Hull is a Las Vegas algorithm that has a time complexity of $\\mathcal{O}(n \\log n)$ in expectation for the 2D and 3D case.\nThe $d$-dimensional generalization adds a time complexity factor of $n^{\\lfloor\\frac{d}{2}\\rfloor}$. I don\u0026rsquo;t have great intuition on this expression, but it has to do with the number of facets on a $d$-dimensional object (increasing recursion breadth).\nI don\u0026rsquo;t have great exposure to Quick Hull, but the general idea is that we begin with a \u0026ldquo;starter hull\u0026rdquo; (subset of the convex hull; encompasses a large percentage of points in expectation).\nFor the 2D case, this hull might have $p_1=\\min_x$, $p_2=\\max_x$, and $p_3=\\max_\\text{dist}(p_1p_2)$ (the point that is furthest from the line $p_1p_2$).\nFor the 3D case, this hull might have the same points as in the 2D case plus $p_4=\\max_\\text{dist}(p_1p_2p_3)$ (the point that is furthest from the plane $p_1p_2p_3$)\nThen, for each facet on the current hull (line in 2D; plane in 3D), add the point $p$ (on the other side of the hull) farthest from the facet.\nThis inclusion may break the convexitivity of the current hull. Perform BFS to determine the \u0026ldquo;horizon\u0026rdquo; of $p$ and remove all visited points not in the horizon.\nThe horizon is what you might be able to see if you were to put your eye at $p$. This can be checked using linear algebra magic.\nIf you can see a point $a$ behind a point $b$, then that means $b$ is not in the horizon and causes the hull to be concave.\nRecursively repeat the previous two steps until every point is enclosed in the hull.\n","date":"2023-07-19T00:00:00Z","image":"https://kiblitz.github.io/p/convex-hull/metal_hucc82ca6d3bed3ea7cfbb5d52fcf5f20d_4026746_120x120_fill_q75_box_smart1.jpeg","permalink":"https://kiblitz.github.io/p/convex-hull/","title":"Convex Hull"},{"content":"Introduction Oftentimes, your program will need to allocate memory on the heap. Unlike the stack where deallocations occur upon scope exiting, something needs to explicitly free memory from the heap.\nIn some languages like $\\texttt{C}$, it is the programmer\u0026rsquo;s responsibility to call $\\texttt{free}$ when it is no longer needed. Manual memory leak debugging and tests were required (i.e. valgrind).\nA lot of higher-level programming languages have a \u0026ldquo;garbage collector\u0026rdquo; (gc). Aptly named, they execute independently of the main program and free memory that is no longer being used (garbage).\nTechniques Garbage collection is a difficult task. There is a juggling tradeoff between the completeness of the gc (what leaks can we allow) versus the resource complexity of the gc (time, space, processing).\nReference Counting For every allocated piece of memory, store a referencing counter representing the number of pointers that point to it. If it ever reaches $0$, free the memory chunk.\nAlgorithm $$ \\begin{align*} \u0026amp;\\texttt{on new $M$:}\\newline \u0026amp;\\texttt{\\qquad $M$.ref\\_count = 1}\\newline \u0026amp;\\newline \u0026amp;\\texttt{on $x$ = $M$:}\\newline \u0026amp;\\texttt{\\qquad $M$.ref\\_count++}\\newline \u0026amp;\\newline \u0026amp;\\texttt{on ($x$ = $M$) out of scope:}\\newline \u0026amp;\\texttt{\\qquad $M$.ref\\_count--}\\newline \u0026amp;\\texttt{\\qquad if $M$.ref\\_count = 0}\\newline \u0026amp;\\texttt{\\qquad \\qquad free($M$)}\\newline \u0026amp;\\texttt{\\qquad \\qquad recurse out-of-scope check on $M$ fields} \\end{align*} $$\nPros Very simple to implement No background thread running in background (all operations are triggered) Cons Word overhead for storing $\\texttt{ref\\_count}$ per allocated memory block Chain overhead when freeing a linked data structure A B C D E F Imagine $\\texttt{A}$ is freed. Then, $\\texttt{B}$ is freed. Then, $\\texttt{C}$ is freed. And so on. So there is a potential high overhead when freeing linked data structures (program pause).\nCycles leak memory A D B C These nodes point to each other. So, their $\\texttt{ref\\_count}$ will never be $0$ even if nothing else in the program points to them (should be garbage).\nPython uses reference counting for its gc. Watch it leak by making a large number of cycle structures.\nMark Sweep For every allocated block of memory, store a mark bit (initialized to $0$). Every now and then, mark all memory that have pointers to them within the current program scope. Free all allocated memory that has not been marked (cannot be accessed $\\implies$ garbage). Unmark all marks.\nAlgorithm $$ \\begin{align*} \u0026amp;\\texttt{let markRecurse(ptr $p$):}\\newline \u0026amp;\\texttt{\\qquad if $p$ is marked then return}\\newline \u0026amp;\\texttt{\\qquad mark $p$}\\newline \u0026amp;\\texttt{\\qquad for all pointers $f$ that are fields of $p$:}\\newline \u0026amp;\\texttt{\\qquad \\qquad markRecurse($f$)}\\newline \u0026amp;\\newline \u0026amp;\\texttt{on gc trigger:}\\newline \u0026amp;\\texttt{\\qquad pause program}\\newline \u0026amp;\\newline \u0026amp;\\texttt{\\qquad // mark phase}\\newline \u0026amp;\\texttt{\\qquad for all pointers $p$ in scope:}\\newline \u0026amp;\\texttt{\\qquad \\qquad markRecurse($p$)}\\newline \u0026amp;\\newline \u0026amp;\\texttt{\\qquad // sweep phase}\\newline \u0026amp;\\texttt{\\qquad for all allocated memory blocks $b$:}\\newline \u0026amp;\\texttt{\\qquad \\qquad if $b$ is marked then free($b$)}\\newline \u0026amp;\\texttt{\\qquad \\qquad unmark $b$}\\newline \u0026amp;\\newline \u0026amp;\\texttt{\\qquad resume program} \\end{align*} $$\nThe gc trigger is heuristical. It could be based on time intervals, memory utilization, processor utilization, etc.\nPros The gc will collect all garbage Cons Long pauses when gc is running Copy Collection Divide the heap into two equal sections: from and to. For every allocated block of memory, store a \u0026ldquo;forwarding address\u0026rdquo; (initialized to $0$). All newly allocated blocks are placed in the from space. Once full, the gc is triggered. It moves all non-garbage blocks to the to space and frees the from space. Then, it swaps the from and to space labels.\nAlgorithm $$ \\begin{align*} \u0026amp;\\texttt{let copyRecurse(ptr $p$):}\\newline \u0026amp;\\texttt{\\qquad if $p$ has no forwarding address:}\\newline \u0026amp;\\texttt{\\qquad \\qquad let $m$ = next available block in $to$ space}\\newline \u0026amp;\\texttt{\\qquad \\qquad copy non-ptr fields of $p$ into $m$}\\newline \u0026amp;\\texttt{\\qquad \\qquad $p$ forwarding address = $m$ (in $from$ space)}\\newline \u0026amp;\\texttt{\\qquad \\qquad for all ptr fields $f$ of $p$:}\\newline \u0026amp;\\texttt{\\qquad \\qquad \\qquad $f$ forwarding address = copyRecurse($f$)}\\newline \u0026amp;\\texttt{\\qquad return $p$ forwarding address}\\newline \u0026amp;\\newline \u0026amp;\\texttt{on gc trigger:}\\newline \u0026amp;\\texttt{\\qquad pause program}\\newline \u0026amp;\\newline \u0026amp;\\texttt{\\qquad for all pointers $p$ in scope:}\\newline \u0026amp;\\texttt{\\qquad \\qquad copyRecurse($p$)}\\newline \u0026amp;\\texttt{\\qquad free($from$ space)}\\newline \u0026amp;\\newline \u0026amp;\\texttt{\\qquad swap $to$ and $from$ labels}\\newline \u0026amp;\\newline \u0026amp;\\texttt{\\qquad resume program} \\end{align*} $$\nThe \u0026ldquo;forwarding address\u0026rdquo; is for the gc to move cyclical data structures to the to space.\nWithout it, recursing on pointers to blocks already in the to space will move the same block again (essentially duplicating it infinitely in the to space).\nf f r r o o m A B m A B t t o o A B f f r r o o m A B m A B t t o A o A B A Example f f r r o o m A B m t t o o A B f t r o o m B t f o A r A B o m Pros The gc will collect all garbage Efficient memory utilization (all allocations are contiguous: no fragmentation) Only $1$ iteration (as opposed to $2$ from mark/sweep) Cons Long pauses when gc is running Only half of the heap can be operated on at a time Lifetime Optimization A general analysis of programs yields the following result.\nAllocated memory blocks that live past a certain point tend to live a really long time Other blocks tend to be short lived This sort of makes sense. These long lasting blocks are likely to be data structures that persist throughout the program. On the other hand, short lived blocks might be temporaries that we only need for a scope (i.e. within function).\nAn optimization to employ is generational collection. The heap is divided into two sections: nursery and tenured.\nn u [ r n s e e w r ] y t e [ n o u l r d e ] d All newly allocated blocks are placed in the nursery. When a nursery gc triggers and cleans up the trash, all blocks that were not cleaned up are \u0026ldquo;promoted\u0026rdquo; to live in the tenured space. There is also a tenured gc, but that executes less frequently than the nursery gc (since those blocks are less likely to be garbage). Observe that after a nursery gc execution, the entire nursery is freed. Much like in copy collection, we can just reclaim the entire space at once rather than for each individual block.\nType Unsafe Problem Lots of higher-level programming languages have type systems that keep code \u0026ldquo;safe\u0026rdquo;. In a lower-level language like $\\texttt{C/C++}$, anything goes. Specifically, any piece of data could be casted to a pointer.\nFor instance, $\\texttt{int x = 5}$ could technically also be a pointer to the memory address $\\texttt{0x5}$.\nAn approach is to employ conservative collection. Any data in scope is conservatively considered to be a pointer. If there exists allocated memory at the address specified by that data, then consider it \u0026ldquo;not garbage\u0026rdquo; (don\u0026rsquo;t free it).\nIf we had $\\texttt{int x = 5}$ and there was $\\texttt{Object obj}$ allocated at address $\\texttt{0x4}$ with size $\\texttt{0x8}$, then consider $\\texttt{obj}$ to be in use.\nThe reason being is that we could technically use $\\texttt{x}$ to access $\\texttt{obj}$, so we can\u0026rsquo;t deem $\\texttt{obj}$ as garbage yet.\nIt\u0026rsquo;s a conservative approach because the gc might falsely mark a piece of memory as still in use, thus leaking it.\n","date":"2023-07-17T00:00:00Z","image":"https://kiblitz.github.io/p/garbage-collection/garbage_hu7d8e2c49ec3f83d7a49149b6e4e77e19_1148135_120x120_fill_q75_box_smart1.jpg","permalink":"https://kiblitz.github.io/p/garbage-collection/","title":"Garbage Collection"},{"content":"Introduction As implied by the name, phantom types are defined by type parameters that are not actually used in implementation. Instead, they are used by the type system to restrict operations on that type. We can use them to improve program correctness (by the type checker).\nExamples Units Suppose we want to have a type for measurement units.\nDefinition $$ \\begin{align*} \u0026amp;\\texttt{module Unit : sig}\\newline \u0026amp;\\texttt{\\qquad type \u0026lsquo;a t}\\newline \u0026amp;\\texttt{\\qquad val of\\_float : float -\u0026gt; \u0026lsquo;a t}\\newline \u0026amp;\\texttt{\\qquad val (+.) : \u0026lsquo;a t -\u0026gt; \u0026lsquo;a t -\u0026gt; \u0026lsquo;a t}\\newline \u0026amp;\\texttt{end = struct}\\newline \u0026amp;\\texttt{\\qquad type \u0026lsquo;a t = float}\\newline \u0026amp;\\texttt{\\qquad let of\\_float x = x}\\newline \u0026amp;\\texttt{\\qquad let (+.) = (+.)}\\newline \u0026amp;\\texttt{end} \\end{align*} $$\nThe module syntax is for defining stuff (in this case types and functions) in a context. So you would have to call $\\texttt{of\\_float}$ with $\\texttt{Unit.of\\_float}$.\n$\\texttt{sig}$ represents the module signature and $\\texttt{struct}$ represents its actual definition (you can have multiple $\\texttt{struct}$ definitions for a single $\\texttt{sig}$).\n$\\texttt{(+.)}$ is just an infix operator for float addition. Here, we define it for operations involving two values of type $\\texttt{Unit}$.\nNotice how $\\texttt{\u0026lsquo;a}$ is never actually used: its underlying type is just a $\\texttt{float}$. However, notice that $\\texttt{(+.)}$ has type $\\texttt{\u0026lsquo;a t -\u0026gt; \u0026lsquo;a t -\u0026gt; \u0026lsquo;a t}$. This means that the two parameters we pass into $\\texttt{(+.)}$ better have the same $\\texttt{\u0026lsquo;a}$ type parameter. Similarly, it will return a value with that same $\\texttt{\u0026lsquo;a}$.\nUse $$ \\begin{align*} \u0026amp;\\texttt{type meters}\\newline \u0026amp;\\texttt{type lbs}\\newline \u0026amp;\\newline \u0026amp;\\texttt{open Unit}\\newline \u0026amp;\\texttt{let m1 : meters t = of\\_float 2.}\\newline \u0026amp;\\texttt{let m2 : meters t = of\\_float 4.}\\newline \u0026amp;\\texttt{let p1 : lbs t = of\\_float 3.}\\newline \u0026amp;\\texttt{let p2 : lbs t = of\\_float 5.}\\newline \u0026amp;\\texttt{let total\\_m = m1 +. m2}\\newline \u0026amp;\\texttt{let total\\_p = p1 +. p2} \\end{align*} $$\n$\\texttt{open Unit}$ just allows us to access $\\texttt{Unit}$ things without prepending them.\nNotice how $\\texttt{meter}$ and $\\texttt{lbs}$ are never actually used outside of declaring types. This is how we can enforce that $\\texttt{(+.)}$ operations can never be used on different units.\nIf you try to add units with different $\\texttt{\u0026lsquo;a}$ parameter types, your program will fail to type check.\n$$\\cancel{\\texttt{total\\_m (+.) total\\_p}}$$\nAlso, if you try to instantiate a variable with a phantom type without the explicit $\\texttt{\u0026lsquo;a}$, your program will also fail to type check.\n$$\\cancel{\\texttt{let x = of\\_float 6.}}$$\nAccess Control This example was inspired by a Ron Minsky post.\nSuppose we want to have a type for reference cells that have access control permissions (read and read/write).\nReference cells allow for mutable values by storing them as addresses containing the data.\n$\\texttt{let x = ref 10}$ creates a reference cell $\\texttt{x}$ storing the value $\\texttt{10}$. $\\texttt{x := 4}$ sets the value in $\\texttt{x}$ to $\\texttt{4}$. $\\texttt{let v = !x}$ extracts the value in $\\texttt{x}$ (so $\\texttt{v = 4}$). Definition $$ \\begin{align*} \u0026amp;\\texttt{type read}\\newline \u0026amp;\\texttt{type write}\\newline \u0026amp;\\newline \u0026amp;\\texttt{module Ref : sig}\\newline \u0026amp;\\texttt{\\qquad type (\u0026lsquo;a, \u0026lsquo;b) t}\\newline \u0026amp;\\texttt{\\qquad create : \u0026lsquo;b -\u0026gt; (write, \u0026lsquo;b) t}\\newline \u0026amp;\\texttt{\\qquad set : (write, \u0026lsquo;b) t -\u0026gt; \u0026lsquo;b -\u0026gt; unit}\\newline \u0026amp;\\texttt{\\qquad get : (\u0026lsquo;a, \u0026lsquo;b) t -\u0026gt; \u0026lsquo;b}\\newline \u0026amp;\\texttt{\\qquad readonly : (\u0026lsquo;a, \u0026lsquo;b) t -\u0026gt; (read, \u0026lsquo;b) t}\\newline \u0026amp;\\texttt{end = struct}\\newline \u0026amp;\\texttt{\\qquad type (\u0026lsquo;a, \u0026lsquo;b) t = \u0026lsquo;b ref}\\newline \u0026amp;\\texttt{\\qquad create x = ref x}\\newline \u0026amp;\\texttt{\\qquad set t x = t := x}\\newline \u0026amp;\\texttt{\\qquad get x = !x}\\newline \u0026amp;\\texttt{\\qquad readonly x = x}\\newline \u0026amp;\\texttt{end} \\end{align*} $$\n$\\texttt{\u0026lsquo;a}$ is discarded in the definition of $\\texttt{Ref}$ (what makes it a phantom type). $\\texttt{\u0026lsquo;b}$ just makes it polymorphic.\nPolymorphic just means that the underlying type of the data within the cell can be anything. In the use example below, we will use $\\texttt{\u0026lsquo;b = int}$.\nAs shown, $\\texttt{Ref}$ has $\\texttt{\u0026lsquo;a = write}$ access upon creation, and you can only call $\\texttt{set}$ on a $\\texttt{Ref}$ which has $\\texttt{\u0026lsquo;a = write}$. Additionally, you can cast any $\\texttt{Ref}$ to have $\\texttt{\u0026lsquo;a = read}$ using $\\texttt{readonly}$ without actually changing any of its underlying data (just its $\\texttt{\u0026lsquo;a}$ parameter type).\nUse $$ \\begin{align*} \u0026amp;\\texttt{open Ref}\\newline \u0026amp;\\texttt{let write\\_ref = create 10}\\newline \u0026amp;\\texttt{let read\\_ref = readonly write\\_ref}\\newline \u0026amp;\\texttt{let value1 = get write\\_ref}\\newline \u0026amp;\\texttt{let () = set write\\_ref 4}\\newline \u0026amp;\\texttt{let value2 = get read\\_ref} \\end{align*} $$\nIf you try to call $\\texttt{set}$ on a $\\texttt{Ref}$ with $\\texttt{\u0026lsquo;a = readonly}$, your program will fail to type check.\n$$\\cancel{\\texttt{set read\\_ref 4}}$$\n","date":"2023-07-16T00:00:00Z","image":"https://kiblitz.github.io/p/phantom-types/ghost_hu7031b9d92fe138160e1775fbc1145b94_7673394_120x120_fill_q75_box_smart1.jpeg","permalink":"https://kiblitz.github.io/p/phantom-types/","title":"Phantom Types"},{"content":"Definition Monads are structures that wrap values. They are useful for creating computation pipelines that abstract away control flow and side effects.\nReturn and Bind A monad of type $\\texttt{\u0026lsquo;a t}$ has the following functions.\n$$ \\begin{align*} \u0026amp;\\texttt{return: \u0026lsquo;a -\u0026gt; \u0026lsquo;a t}\\newline \u0026amp;\\texttt{bind: \u0026lsquo;a t -\u0026gt; (\u0026lsquo;a -\u0026gt; \u0026lsquo;b t) -\u0026gt; \u0026lsquo;b t} \\end{align*} $$\nMonads are parametric types. $\\texttt{t}$ represents the monad itself and $\\texttt{\u0026lsquo;a}$ is the type parameter.\nFor example, $\\texttt{Option}$ is a monad. The value it wraps has the parameter type $\\texttt{\u0026lsquo;a}$. So, you could have types like $\\texttt{int Option}$ or $\\texttt{string Option}$.\n$\\texttt{\u0026lsquo;b}$ is another parameter. Bind takes a function that essentially \u0026ldquo;maps\u0026rdquo; the current monad type parameter $\\texttt{\u0026lsquo;a}$ to another monad of type $\\texttt{\u0026lsquo;b}$.\nIt helps to follow the types. $\\texttt{return}$ constructs the monad from a value. $\\texttt{bind}$ transforms the value within the monad (computation pipeline).\nMap The definition for the monadic function $\\texttt{map}$ follows from the functions above.\n$$ \\begin{align*} \u0026amp;\\texttt{map: \u0026lsquo;a t -\u0026gt; (\u0026lsquo;a -\u0026gt; \u0026lsquo;b) -\u0026gt; \u0026lsquo;b t}\\newline \u0026amp;\\newline \u0026amp;\\texttt{let map t f =}\\newline \u0026amp;\\texttt{\\qquad let g a = return (f a) in}\\newline \u0026amp;\\texttt{\\qquad bind t g} \\end{align*} $$\n$\\texttt{map}$ is the same as $\\texttt{bind}$ except the function ($\\texttt{f}$) returns a raw $\\texttt{\u0026lsquo;b}$ rather than a $\\texttt{\u0026lsquo;b t}$.\nHere, we construct the $\\texttt{g}$ necessary for $\\texttt{bind}$ by just applying $\\texttt{return}$ to the result of $\\texttt{f}$.\nOCaml ppx_let The ppx_let library for OCaml provides an elegant way to code with monads.\nAlthough The ppx_let library introduces various monadic syntax (i.e. monadic pattern matching), we will only display monadic let bindings.\nThey work similarly to these monadic let bindings (see documentation).\n$$ \\begin{align*} \u0026amp;\\texttt{let\\%bind a = a\\_monad in (* a : \u0026lsquo;a; a\\_monad : \u0026lsquo;a t *)}\\newline \u0026amp;\\texttt{\\qquad \u0026hellip;}\\newline \u0026amp;\\texttt{\\qquad b\\_monad (* b\\_monad : \u0026lsquo;b t *)} \\end{align*} $$\n$\\texttt{(* \u0026hellip; *)}$ are comments.\nWith this syntactic sugar, we define the function parameter in (call it $\\texttt{f}$ with type $\\texttt{\u0026lsquo;a -\u0026gt; \u0026lsquo;b t}$) in the body of the $\\texttt{let\\%bind}$, where $\\texttt{a}$ is the parameter to $\\texttt{f}$.\n$$ \\begin{align*} \u0026amp;\\texttt{let\\%map a = a\\_monad in (* a : \u0026lsquo;a; a\\_monad : \u0026lsquo;a t *)}\\newline \u0026amp;\\texttt{\\qquad \u0026hellip;}\\newline \u0026amp;\\texttt{\\qquad b (* b : \u0026lsquo;b *)} \\end{align*} $$\n$\\texttt{let\\%map}$ does basically the same thing except the return type of its body is just a $\\texttt{\u0026lsquo;b}$ (as is in $\\texttt{f}$ with type $\\texttt{\u0026lsquo;a -\u0026gt; \u0026lsquo;b}$).\nThese might be easier to grasp with the examples below.\nImportant to note that the type of the entire $\\texttt{let\\%bind}$ and $\\texttt{let\\%map}$ expressions are $\\texttt{\u0026lsquo;b t}$, consistent with the return types of $\\texttt{bind}$ and $\\texttt{map}$.\nTypically, to chain monadic operations we will end with a single $\\texttt{let\\%map}$. All previous bindings will be $\\texttt{let\\%bind}$.\n$$ \\begin{align*} \u0026amp;\\texttt{let\\%bind a = a\\_monad in}\\newline \u0026amp;\\texttt{let\\%bind b = b\\_monad in}\\newline \u0026amp;\\texttt{let\\%bind c = c\\_monad in}\\newline \u0026amp;\\texttt{let\\%map d = d\\_monad in}\\newline \u0026amp;\\texttt{(a, b, c, d)} \\end{align*} $$\nWhy is this the case?\n$\\texttt{let\\%bind}$ expects its function parameter to return a monad, which both $\\texttt{let\\%bind}$ and $\\texttt{let\\%map}$ do. This is why all except the last level must be $\\texttt{let\\%bind}$. It is natural to perform computations without monads. Since this usually occurs after \u0026ldquo;unwrapping\u0026rdquo; all the monads, the last level is usually a $\\texttt{let\\%map}$. Note that if the last level were a $\\texttt{let\\%bind}$, we would have to return a monad.\n$$ \\begin{align*} \u0026amp;\\texttt{let\\%bind a = a\\_monad in}\\newline \u0026amp;\\texttt{let\\%bind b = b\\_monad in}\\newline \u0026amp;\\texttt{let\\%bind c = c\\_monad in}\\newline \u0026amp;\\texttt{let\\%bind d = d\\_monad in}\\newline \u0026amp;\\texttt{return (a, b, c, d)} \\end{align*} $$\nExamples Option Definition Options give optionality to the existence of an underlying value.\n$$ \\begin{align*} \u0026amp;\\texttt{type \u0026lsquo;a Option =}\\newline \u0026amp;\\texttt{\\quad | None}\\newline \u0026amp;\\texttt{\\quad | Some of \u0026lsquo;a}\\newline \u0026amp;\\newline \u0026amp;\\texttt{let return a = Some a }\\newline \u0026amp;\\texttt{let bind a\\_opt f =}\\newline \u0026amp;\\texttt{\\qquad match a\\_opt with}\\newline \u0026amp;\\texttt{\\qquad \\qquad None -\u0026gt; None}\\newline \u0026amp;\\texttt{\\qquad \\quad | Some a -\u0026gt; f a} \\end{align*} $$\nUse Suppose we want to implement the $\\texttt{option\\_plus}$ function which operates on two parameters of type $\\texttt{int Option}$.\n$$ \\begin{align*} \u0026amp;\\texttt{let option\\_plus (a\\_opt : int Option) (b\\_opt : int Option) : int Option =}\\newline \u0026amp;\\texttt{\\qquad let\\%bind a = a\\_opt in}\\newline \u0026amp;\\texttt{\\qquad let\\%map b = b\\_opt in}\\newline \u0026amp;\\texttt{\\qquad a + b} \\end{align*} $$\nThis is much more elegant than \u0026ldquo;if-statement spamming\u0026rdquo; (or in OCaml, \u0026ldquo;pattern match spamming\u0026rdquo;).\n$$ \\begin{align*} \u0026amp;\\texttt{let option\\_plus (a\\_opt : int Option) (b\\_opt : int Option) : int Option =}\\newline \u0026amp;\\texttt{\\qquad match a\\_opt with}\\newline \u0026amp;\\texttt{\\qquad \\qquad None -\u0026gt; None}\\newline \u0026amp;\\texttt{\\qquad \\quad | Some a -\u0026gt;}\\newline \u0026amp;\\texttt{\\qquad \\qquad (match b\\_opt with}\\newline \u0026amp;\\texttt{\\qquad \\qquad \\qquad None -\u0026gt; None}\\newline \u0026amp;\\texttt{\\qquad \\quad \\qquad | Some b -\u0026gt; a + b)} \\end{align*} $$\nResult Definition Results allow values to have a fail condition. They are like options except we can tag the $\\texttt{None}$ case with information (i.e. error information).\n$$ \\begin{align*} \u0026amp;\\texttt{type (\u0026lsquo;a, \u0026lsquo;b) Result =}\\newline \u0026amp;\\texttt{\\quad | Ok of \u0026lsquo;a}\\newline \u0026amp;\\texttt{\\quad | Error of \u0026lsquo;b}\\newline \u0026amp;\\newline \u0026amp;\\texttt{let return a = Ok a }\\newline \u0026amp;\\texttt{let bind a\\_res f =}\\newline \u0026amp;\\texttt{\\qquad match a\\_res with}\\newline \u0026amp;\\texttt{\\qquad \\qquad Ok a -\u0026gt; f a}\\newline \u0026amp;\\texttt{\\qquad \\quad | Error \\_ as err -\u0026gt; err} \\end{align*} $$\nThe $\\texttt{Error \\_ as err -\u0026gt; err}$ just assigns the entire result into $\\texttt{err}$. Alternatively, we could have written $\\texttt{Error e -\u0026gt; Error e}$.\nUse Suppose we have a function $\\texttt{input: unit -\u0026gt; string}$ which reads from $\\texttt{stdin}$.\nThe $\\texttt{unit}$ type has only one possible value: $\\texttt{()}$. It is useful for when we want a function that requires zero arguments.\nSuppose we have a function which attempts to convert a $\\texttt{string}$ to an $\\texttt{int}$ and stores the error as a $\\texttt{string}$.\n$$\\texttt{atoi: string -\u0026gt; (int, string) Result}$$\nNow, let\u0026rsquo;s write a function to add two user inputs.\n$$ \\begin{align*} \u0026amp;\\texttt{let add\\_user\\_inputs (() : unit) : (int, string) Result =}\\newline \u0026amp;\\texttt{\\qquad let\\%bind a = input () |\u0026gt; atoi in}\\newline \u0026amp;\\texttt{\\qquad let\\%map b = input () |\u0026gt; atoi in}\\newline \u0026amp;\\texttt{\\qquad a + b} \\end{align*} $$\n$\\texttt{input () |\u0026gt; atoi}$ is syntactic sugar for $\\texttt{atoi (input ())}$\nDeferred Definition Deferreds allow us to make asynchronous computation. The implementation is a bit more involved, since the idea is computation is queued to a scheduler within a deferred monad. For this reason, the following code is pseudocode.\n$$ \\begin{align*} \u0026amp;\\texttt{type \u0026lsquo;a Deferred =}\\newline \u0026amp;\\texttt{\\quad | Determined of \u0026lsquo;a}\\newline \u0026amp;\\texttt{\\quad | Undetermined}\\newline \u0026amp;\\newline \u0026amp;\\texttt{let return a = Determined a }\\newline \u0026amp;\\texttt{let bind a\\_def f = \u0026hellip;}\\newline \u0026amp;\\texttt{(* f is queued on the scheduler. The return value of the bind}\\newline \u0026amp;\\texttt{ * (call it x) resolves immediately to undetermined. Upon f\u0026rsquo;s}\\newline \u0026amp;\\texttt{ * execution completion, x becomes a determined. Monadic chains}\\newline \u0026amp;\\texttt{ * (bind to bind to \u0026hellip; to bind to map) continue asynchronously}\\newline \u0026amp;\\texttt{ * on x.}\\newline \u0026amp;\\texttt{ *}\\newline \u0026amp;\\texttt{ * These deferred monadic chains are \u0026ldquo;upon\u0026rdquo; computations.}\\newline \u0026amp;\\texttt{ *)}\\newline \\end{align*} $$\nUse Suppose we have a function write a function to crawl a webpage and click all links and print visited urls. The function halts once it has reached a given depth (all links on the first page result have depth $1$; all of their links have depth $2$; etc).\nHere are the functions we are given to use:\n$\\texttt{print: string -\u0026gt; unit}$ outputs to $\\texttt{stdout}$ $\\texttt{curl: string -\u0026gt; string Deferred}$ queries the web for an html page given its web address $\\texttt{get\\_links: string -\u0026gt; string List}$ grabs a list of all links on an html page $\\texttt{List.map: \u0026lsquo;a List -\u0026gt; (\u0026lsquo;a -\u0026gt; \u0026lsquo;b) -\u0026gt; \u0026lsquo;b List}$ takes a list of items and performs a computation on all of its elements $\\texttt{Deferred.all: \u0026lsquo;a Deferred List -\u0026gt; \u0026lsquo;a List Deferred}$ transforms a list of deferreds into a single deferred holding a list Notice the $\\texttt{List.map}$. Indeed there exists a list monad! We will not be covering it.\n$$ \\begin{align*} \u0026amp;\\texttt{let crawl (i : int) (url : string) : unit Deferred =}\\newline \u0026amp;\\texttt{\\qquad let () = print url in}\\newline \u0026amp;\\texttt{\\qquad if i = 0 then return () else}\\newline \u0026amp;\\texttt{\\qquad let j = i - 1 in}\\newline \u0026amp;\\texttt{\\qquad let\\%bind html = curl url in}\\newline \u0026amp;\\texttt{\\qquad let links = get\\_links html in}\\newline \u0026amp;\\texttt{\\qquad let crawls = List.map links (crawl j) in}\\newline \u0026amp;\\texttt{\\qquad let\\%map (\\_ : unit List) = Deferred.all crawls in}\\newline \u0026amp;\\texttt{\\qquad ()} \\end{align*} $$\nNote that $\\texttt{crawl}$ is non-blocking. If we call it, it will immediately return a $\\texttt{unit Deferred}$ and we can continue the program ($\\texttt{crawl}$ is queued by the scheduler). If at any point, we want to block until $\\texttt{crawl}$ completes, we can monadic bind on the $\\texttt{unit Deferred}$ return value.\n$$ \\begin{align*} \u0026amp;\\texttt{let unit\\_def = crawl 5 \u0026ldquo;https://www.wikipedia.org\u0026rdquo; in}\\newline \u0026amp;\\texttt{(* \u0026hellip; do some stuff \u0026hellip; *)}\\newline \u0026amp;\\texttt{let\\%map () = unit\\_def in ()}\\newline \\end{align*} $$\n","date":"2023-07-15T00:00:00Z","image":"https://kiblitz.github.io/p/monads/abstract1_hu0669468fe9f20b44a7a02abdb1eea740_1661783_120x120_fill_box_smart1_3.png","permalink":"https://kiblitz.github.io/p/monads/","title":"Monads"},{"content":"Introduction Suppose a class and its two children have the following structures.\n$$ \\begin{align*} \u0026amp;\\texttt{class Pet:}\\newline \u0026amp;\\texttt{\\qquad string name}\\newline \u0026amp;\\texttt{\\qquad int age} \u0026amp;\\newline \u0026amp;\\newline \u0026amp;\\texttt{class Cat extends Pet:}\\newline \u0026amp;\\texttt{\\qquad string catBreed}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{class Dog extends Pet:}\\newline \u0026amp;\\texttt{\\qquad string dogBreed} \\end{align*} $$\nSo maybe a person wants to keep track of their pets. Since both $\\texttt{Cat}$ and $\\texttt{Dog}$ are subtypes of $\\texttt{Pet}$, we can store them in a $\\texttt{Pet}$ array.\n$$\\texttt{Pet[] pets}$$\nNote that elements in $\\texttt{pets}$ won\u0026rsquo;t know if they are a $\\texttt{Cat}$ or $\\texttt{Dog}$ so we can only access fields that belong to $\\texttt{Pet}$ ($\\texttt{name}$ and $\\texttt{age}$).\nSingle Inheritance If a $\\texttt{Pet}$ doesn\u0026rsquo;t know if it is a $\\texttt{Cat}$ or a $\\texttt{Dog}$, we need to make sure that the procedure for accessing $\\texttt{name}$ and $\\texttt{age}$ is the same in both of its children.\nFields What if we put the parent ($\\texttt{Pet}$) fields at the top of the memory structure.\np n e a a t m g e e * c a n t c a a B a m g r t e e e * e d * d o n g d a a B o m g r g e e e * e d * Strings are just pointers (*) since there is no bound on string length.\nNow, no matter what a $\\texttt{Pet pet}$ actually is, $\\texttt{pet+0x0}$ is going to be $\\texttt{name}$, and $\\texttt{pet+0x8}$ is going to be $\\texttt{age}$.\nThis is in our theoretical memory model, though the effect would be similar in your favorite programming language.\nNon-virtual Functions Think of non-virtual functions as just normal class methods. We will discuss virtual functions afterwards.\nNow, let\u0026rsquo;s add a function to our class hierarchy.\n$$ \\begin{align*} \u0026amp;\\texttt{class Pet:}\\newline \u0026amp;\\texttt{\\qquad string name}\\newline \u0026amp;\\texttt{\\qquad int age}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{\\qquad void noise():}\\newline \u0026amp;\\texttt{\\qquad\\qquad print(\u0026ldquo;pet noises\u0026rdquo;)} \\end{align*} $$\nCould we do the same thing?\nn . n p n o d o e a a i a i t m g s t s e e e a e * * c a n n t c a a o B a m g i r t e e s e * e e * d * d o n n g d a a o B o m g i r g e e s e * e e * d * $\\texttt{.data}$ just stores the function definition.\nWhile this is correct, we can optimize based on the observation that method definitions are shared between all objects of the same class.\nFirst, note that a method call $\\texttt{pet.noise()}$ is syntactic sugar for $\\texttt{Pet.noise(pet)}$ (object is passed as parameter). Since $\\texttt{noise}$ is not specific to the object $\\texttt{pet}$, it can be resolved at compile-time.\n. n p n d o e a a a i t m g t s e e a e * c a n t c a a B a m g r t e e e * e d * d o n g d a a B o m g r g e e e * e d * Everytime $\\texttt{Pet.noise(pet)}$ is called, just replace it (at compile-time) with the known address of $\\texttt{Pet.noise}$ (in our memory model: $\\texttt{.data+0x0}$).\nFor example:\n$$ \\begin{align*} \u0026amp;\\texttt{Cat cat}\\newline \u0026amp;\\texttt{Dog dog}\\newline \u0026amp;\\texttt{cat.noise()}\\newline \u0026amp;\\texttt{dog.noise()}\\newline \\newline \u0026amp;\\implies\\newline \\newline \u0026amp;\\texttt{Cat cat}\\newline \u0026amp;\\texttt{Dog dog}\\newline \u0026amp;\\texttt{(.data+0x0)(cat)}\\newline \u0026amp;\\texttt{(.data+0x0)(dog)} \\end{align*} $$\nWe save space on every object holding a pointer to $\\texttt{noise}$ ($\\texttt{+0x8}$ size per object).\nVirtual Functions Introduction The heart of inheritance is the concept of a virtual function. The idea is that an inherited method can take different definitions depending on the class hierarchy lineage.\nLet\u0026rsquo;s take our code from above and modify it so that $\\texttt{noise}$ is a virtual function.\nOther class data omitted.\n$$ \\begin{align*} \u0026amp;\\texttt{class Pet:}\\newline \u0026amp;\\texttt{\\qquad void noise():}\\newline \u0026amp;\\texttt{\\qquad\\qquad print(\u0026ldquo;pet noises\u0026rdquo;)}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{class Cat extends Pet:}\\newline \u0026amp;\\texttt{\\qquad void noise():}\\newline \u0026amp;\\texttt{\\qquad\\qquad print(\u0026ldquo;meow\u0026rdquo;)}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{class Dog extends Pet:}\\newline \u0026amp;\\texttt{\\qquad void noise():}\\newline \u0026amp;\\texttt{\\qquad\\qquad print(\u0026ldquo;bark\u0026rdquo;)} \\end{align*} $$\nThe children can override the definition of a virtual method (in this case, $\\texttt{noise}$).\nNote that if the child does not provide a definition override, it keeps the parent\u0026rsquo;s definition (recursively).\n$$ \\begin{align*} \u0026amp;\\texttt{class Fish extends Pet:}\\newline \u0026amp;\\texttt{\\qquad string color}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{Fish fish}\\newline \u0026amp;\\texttt{fish.noise()\\qquad\\thickspace\\thickspace// \u0026ldquo;pet noises\u0026rdquo;}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{class Betta extends Fish:}\\newline \u0026amp;\\texttt{\\qquad string bettaSpecies}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{Betta betta}\\newline \u0026amp;\\texttt{betta.noise()\\qquad// \u0026ldquo;pet noises\u0026rdquo;} \\end{align*} $$\nThe issue now is that we cannot know at compile-time which virtual function (in this case $\\texttt{noise}$) to call.\n$$ \\begin{align*} \u0026amp;\\texttt{Pet[] pets = [Cat(), Dog()]}\\newline \u0026amp;\\texttt{pets[0].noise()\\qquad// Cat.noise() -\u0026gt; \u0026ldquo;meow\u0026rdquo;}\\newline \u0026amp;\\texttt{pets[1].noise()\\qquad// Dog.noise() -\u0026gt; \u0026ldquo;bark\u0026rdquo;} \\end{align*} $$\nOne (naive) solution is to again provide the function pointer as part of the object\u0026rsquo;s structure.\nP P C D e e a o t . t t g p n . d . . . e a a n a n n n t m g o t o o o e e i a i i i * s s s s e e e e * C a c t a c n . t a a a n B t m g o r e e i e * s e e d * * D o d g o d n . g o a a n B g m g o r e e i e * s e e d * * But again, objects of the same type share the same set of virtual functions (every $\\texttt{Cat}$ is going to have the same $\\texttt{noise=cat+0x10}$ value).\nVtable Enter the virtual method table. Every object in a class hierarchy (with virtual methods) now also contains a pointer (virtual pointer) to a table (virtual table) containing all of the virtual methods.\nP P P P C D e e e e a o t t t . t t g p . n . . d . . . e v a a v n a n n n t t m g t o t o o o a e e a i a i i i b * b s s s s l l e e e e e e * * C C C a a a c t t t a . . . n t v n c v a a B t o a t m g r a i t a e e e b s b * e l e l d e * e * * D D D o o o d g g g o . . . n g v n d v a a B t o o t m g r a i g a e e e b s b * e l e l d e * e * * In this case, there is more memory used than in our naive approach. But for every additional virtual function, under the naive approach every object increases in size linearly.\nWith vtables, only the appropriate vtable sizes increase (and it is expected that there are significantly less vtables than object instances).\n$$ \\begin{align*} \u0026amp;\\texttt{Pet[] pets = [Cat(), Dog()]}\\newline \u0026amp;\\texttt{pets[0].noise()}\\newline \u0026amp;\\texttt{pets[1].noise()}\\newline \u0026amp;\\texttt{/* }\\newline \u0026amp;\\texttt{ * vptr = pets[\\textit{x}]+0x0}\\newline \u0026amp;\\texttt{ * vtable = \\\u0026amp;vptr}\\newline \u0026amp;\\texttt{ * noise = vtable+0x0}\\newline \u0026amp;\\texttt{ */} \\end{align*} $$\nThis also works with inheritance lineages. Suppose that $\\texttt{Pet}$ is a child class of $\\texttt{Thing}$.\nOther class data omitted.\n$$ \\begin{align*} \u0026amp;\\texttt{class Thing:}\\newline \u0026amp;\\texttt{\\qquad string class():}\\newline \u0026amp;\\texttt{\\qquad \\qquad return \u0026ldquo;Thing\u0026rdquo;}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{class Pet extends Thing:}\\newline \u0026amp;\\texttt{\\qquad string class():}\\newline \u0026amp;\\texttt{\\qquad \\qquad return \u0026ldquo;Pet\u0026rdquo;}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{class Dog extends Pet:}\\newline \u0026amp;\\texttt{\\qquad string class():}\\newline \u0026amp;\\texttt{\\qquad \\qquad return \u0026ldquo;Dog\u0026rdquo;}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{class Cat extends Pet:}\\newline \u0026amp;\\texttt{\\qquad string class():}\\newline \u0026amp;\\texttt{\\qquad \\qquad return \u0026ldquo;Cat\u0026rdquo;} \\end{align*} $$\nT P T T P P P T h e h h e e e h P C D P C D i t i i t t t . i e a o e a o n p . n n n . . . d n t t g t t g t g e v a a g g v c n a g . . . . . . h . t t m g . . t l o t . c c c n n n i v a e e v c a a i a c l l l o o o n t b * t l b s s l a a a i i i g a l a a l s e a s s s s s s b e b s e * * s s s s e e e l * l s s e e * * C C C C a a a a c t t t t a . . . . n t v c n c v a a B t l o a t m g r a a i t a e e e b s s b * e l s e l d e * * e * * D D D D o o o o d g g g g o . . . . n g v c n d v a a B t l o o t m g r a a i g a e e e b s s b * e l s e l d e * * e * * The only constraint is that parent virtual functions should be represented in memory before child virtual functions. Doing so keeps an ordering across a lineage. In this case, the $\\texttt{class}$ virtual function will always be at $\\texttt{vtable+0x0}$ for any class that has that function.\nIf a class doesn\u0026rsquo;t have that virtual function, the type checker would catch the error at compile time (i.e. $\\texttt{Thing.noise()}$).\nMultiple Inheritance Introduction New example.\n$$ \\begin{align*} \u0026amp;\\texttt{class Printable:}\\newline \u0026amp;\\texttt{\\qquad string output}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{\\qquad void print():}\\newline \u0026amp;\\texttt{\\qquad \\qquad print(output)}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{class Stringable:}\\newline \u0026amp;\\texttt{\\qquad string value}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{\\qquad string toString():}\\newline \u0026amp;\\texttt{\\qquad \\qquad return value}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{class Person extends Printable, Stringable:}\\newline \u0026amp;\\texttt{\\qquad string name}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{\\qquad void print():}\\newline \u0026amp;\\texttt{\\qquad \\qquad print(output)}\\newline \u0026amp;\\texttt{\\qquad \\qquad print(value)}\\newline \u0026amp;\\texttt{\\qquad \\qquad print(name)}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{\\qquad string toString():}\\newline \u0026amp;\\texttt{\\qquad \\qquad return output + value + name} \\end{align*} $$\nOk, so now we can have two parents. How can we possibly represent this in memory?\nThe Problem What ordering can we keep?\nP P r r P i i r n n i p t t n r a o a t i b u b a n l t l b t e p e l a . u . e b v t v . l t * t p e a a r b b i l l n e e t * S S S t t t r r r i i i n s n n g t g g a r a v a b i b a b l n l l l e g e u e . a . e . t b v * v o l t t S e a a t b b r l l i e e n * g P P e P e r e P r s r e s p o o v s r o e n u a n o s n r . t l a n o . s v p u m . n t o t u e e v . o n a t * * t p S b * a r t l b i r e l n i * e t n g If we put $\\texttt{print}$ first in the $\\texttt{Person}$ vtable, $\\texttt{toString}$ calls and $\\texttt{value}$ accesses fail.\n$$ \\begin{align*} \u0026amp;\\texttt{Stringable[] stringables = [Stringable(), Person()]}\\newline \u0026amp;\\texttt{Stringable[0].toString()}\\newline \u0026amp;\\texttt{Stringable[1].toString()}\\newline \u0026amp;\\texttt{/* }\\newline \u0026amp;\\texttt{ * vptr = stringables[\\textit{x}]+0x0}\\newline \u0026amp;\\texttt{ * vtable = \\\u0026amp;vptr}\\newline \u0026amp;\\texttt{ * toString = vtable+???}\\newline \u0026amp;\\texttt{ * // 0x0 in Stringable.vtable; 0x8 in Person.vtable}\\newline \u0026amp;\\texttt{ */}\\newline \u0026amp;\\newline \u0026amp;\\texttt{Stringable[0].value}\\newline \u0026amp;\\texttt{Stringable[1].value}\\newline \u0026amp;\\texttt{/* }\\newline \u0026amp;\\texttt{ * value = stringables[\\textit{x}]+???}\\newline \u0026amp;\\texttt{ * // 0x0 in Stringable layout; 0x8 in Person layout}\\newline \u0026amp;\\texttt{ */} \\end{align*} $$\nThe Solution Part 1: Contiguous Layout p s P P e t e e P r r P r r r s i r P s s i o n i r o o n n g n i n n p t a t n . . r a o b a t P S i b u l b a r t n l t e l b i r t e p e l n i a . u . e t n b v t v . a g l t * t p b a e a a r l b b b i e l l l n . e e e t v . * P t v P e a t e r b a r s l b s o e l o n e n . . S S S P t S t t r o r t r r i u i v n r i i n t n a a i n s n t p g l m n g t g a u a u e g a r a v b t b e * a b P i b a l * l * b l e n l l e e l e P r g e u . . e . e s a . e v v . t r o b v * t t v o s n l t a a t S o . e a b b a t n t b l l b r . o l e e l i p S e * * e n r t * g i r n i t n g The key idea is this: whenever we pass a $\\texttt{Person}$ where $\\texttt{Stringable}$ is expected, it is replaced at compile-time with the $\\texttt{stringable}$ address $\\texttt{person+0x10}$.\n$$\\begin{align*} \\texttt{\\\u0026amp;person}\u0026amp;\\neq\\texttt{\\\u0026amp;cast\u0026lt;Stringable\u0026gt;(person)}\\newline \\texttt{\\\u0026amp;person+0x10}\u0026amp;=\\texttt{\\\u0026amp;cast\u0026lt;Stringable\u0026gt;(person)} \\end{align*} $$\ns P t e r r i s n o g n a . b S l t e r i n g a b l e . P v e t r a s b o l n e . S t r i v n n a a g l m a u e b e * P l * e e r . s v o t n a . b t l o e S * t r i n g $$ \\begin{align*} \u0026amp;\\texttt{Person person = Person()}\\newline \u0026amp;\\texttt{Stringable[] stringables = [Stringable(), person] // person+0x10}\\newline \u0026amp;\\texttt{Stringable[0].toString()}\\newline \u0026amp;\\texttt{Stringable[1].toString()}\\newline \u0026amp;\\texttt{/* }\\newline \u0026amp;\\texttt{ * vptr = stringables[\\textit{x}]+0x0}\\newline \u0026amp;\\texttt{ * vtable = \\\u0026amp;vptr}\\newline \u0026amp;\\texttt{ * toString = vtable+0x0}\\newline \u0026amp;\\texttt{ */}\\newline \\newline \u0026amp;\\texttt{Stringable[0].value}\\newline \u0026amp;\\texttt{Stringable[1].value}\\newline \u0026amp;\\texttt{/* }\\newline \u0026amp;\\texttt{ * value = stringables[\\textit{x}]+0x8}\\newline \u0026amp;\\texttt{ */} \\end{align*} $$\nRelative memory location is consistent!\nOne problem: how does $\\texttt{Person.toString}$ access $\\texttt{output}$ (a field derived from $\\texttt{Printable}$)?\n$ \\texttt{string Person.toString():}\\newline \\texttt{\\qquad return output + value + name}\\newline \\texttt{\\qquad // output is at person+0x8}\\newline \\texttt{\\qquad // output is lost when using person+0x10}\\newline $\nPart 2: Top Offset p s P P e t e e r r P r r s i r P s s o n i r o o n g n i n n a t n . . b a t P S l b a r t e l 0 b i r e x l n i . 0 e t n v . a g t p b a a r l b b i e l l n . e e t v . P t v P e a t e r b a r s l b s o e l o n e n . . S S P t S t r o r t r i u i v n r i n t n a a i n t p g l m n g a u a u e g a b t b e * a b P l * l * b 0 l e e e l x e P r . . e 0 . e s v v . t r o t t v o s - n a a t S 0 o 0 . b b a t x n x t l l b r 0 . 1 o e e l i p 0 S * * e n r t g i r n i t n g 0 x 1 0 We\u0026rsquo;ve added two new entries to the $\\texttt{Person.vtable}$: the top offsets.\nRecall that $\\texttt{person.toString()}$ is syntactic sugar for $\\texttt{Person.toString(person)}$. So now, when we call functions in the vtable, instead of passing the object address, we pass the object address plus the top offset (which gives a pointer to the original object). This is called this pointer adjustment.\n$$\\begin{align*} \u0026amp;\\texttt{Person person = Person()}\\newline \u0026amp;\\texttt{Stringable[] stringables = [Stringable(), person] // person+0x10}\\newline \u0026amp;\\texttt{Stringable[0].toString()}\\newline \u0026amp;\\texttt{Stringable[1].toString()}\\newline \u0026amp;\\texttt{/* }\\newline \u0026amp;\\texttt{ * vptr = stringables[\\textit{x}]+0x0}\\newline \u0026amp;\\texttt{ * vtable = \\\u0026amp;vptr}\\newline \u0026amp;\\texttt{ * toString = vtable+0x8}\\newline \u0026amp;\\texttt{ * topOffset = *(vtable+0x0)}\\newline \u0026amp;\\texttt{ * this = stringables[\\textit{x}]+topOffset}\\newline \u0026amp;\\texttt{ * toString(this)}\\newline \u0026amp;\\texttt{ */} \\end{align*}$$\nNow, $\\texttt{output}$ is at $\\texttt{this+0x8}$.\nObserve that this works with $\\texttt{Printable}$.\n$$\\texttt{\\\u0026amp;person}=\\texttt{\\\u0026amp;cast\u0026lt;Printable\u0026gt;(person)}$$\nThe $\\texttt{Person.Printable}$ top offset is $\\texttt{0x0}$, so the this pointer adjustment has no effect.\nIn general, if $\\texttt{Child extends A, B, C, D}$:\nC A B C D C C C C C h h h h h h i i i i i i l l l l l l d d d d d d . . . . . v A B C D t . . . . a v v v v b t t t t l a a a a e b b b b l l l l C C C C e e e e C h h h h h i C i C i C i C i C l h l h l h l h l h d i d i d i d i d i . l . l . l . l . l A d B d C d D d v d … . . … . . … . . … . . … t . v A v B v C v D a d t . t . t . t . C C C C b a a d a d a d a d C h h h h l t b a b a b a b a h i i i i e a l t l t l t l t i l l l l * e a e a e a e a l d d d d * * * * d . . . . . A B C D 0 f - . - . - . - . x u … a f … b f … c f … d f … 0 n u u u u c n n n n a t c c c c i t t t t o i i i i b n o o o o s n n n n s s s s c d ","date":"2023-07-14T00:00:00Z","image":"https://kiblitz.github.io/p/dynamic-dispatch/blocks_hu9616bf3caa0d73a3d5bc25029cdd48a0_1391911_120x120_fill_q75_box_smart1.jpg","permalink":"https://kiblitz.github.io/p/dynamic-dispatch/","title":"Dynamic Dispatch: Memory Organization"},{"content":"Introduction At the very least when it comes to types, something of type $\\texttt{A}$ can be used whenever something of type $\\texttt{A}$ is expected.\n$\\texttt{int a = 5}\\newline\\texttt{float b = 5.0}$\nIs there any leeway for flexibility? Specifically, does there exist a notion of type substitutability?\n$\\texttt{float b = 5}$\nThis makes sense because an $\\texttt{int}$ is a subset of a $\\texttt{float}$. In other words, a $\\texttt{float}$ can do anything an $\\texttt{int}$ can do.\n$\\cancel{\\texttt{int b = 5.0}}$\nThis won\u0026rsquo;t work. An $\\texttt{int}$ cannot do everything a $\\texttt{float}$ can do (cannot represent all of its values). A quick way to break this is: $$\\texttt{int b = 5.5}$$\nDefinition $S \u0026lt;: T$ means that $S$ is a subtype of $T$.\nThis means that anything of type $S$ can be used whenever type $T$ is expected.\nSo in the above example: $$\\texttt{int}\u0026lt;:\\texttt{float}$$\nYou can think of it as $S$ is more restrictive (to typecheck) than $T$ since if you want to do something with $T$, you should also be able to do it with $S$.\nStructures Width Subtyping Class Hierarchy Suppose a class lineage has the following structures.\n$$ \\begin{align*} \u0026amp;\\texttt{class Animal:}\\newline \u0026amp;\\texttt{\\qquad string name}\\newline \u0026amp;\\texttt{\\qquad int age}\\newline \u0026amp;\\texttt{\\qquad void}\\rightarrow\\texttt{void makeNoise}\\newline \u0026amp;\\newline \u0026amp;\\texttt{class Mammal extends Animal:}\\newline \u0026amp;\\texttt{\\qquad string furColor}\\newline \u0026amp;\\newline \u0026amp;\\texttt{class Human extends Mammal:}\\newline \u0026amp;\\texttt{\\qquad string occupation}\\newline \u0026amp;\\texttt{\\qquad int netWorth}\\newline \u0026amp;\\texttt{\\qquad void}\\rightarrow\\texttt{int doTaxes} \\end{align*} $$\nBy definition of class hierarchy, a child has every characteristic its parent has. For example, $\\texttt{Human}$ has a $\\texttt{furColor}$, and transitively, since $\\texttt{Mammal}$ has a $\\texttt{name}$ (among other things), so does $\\texttt{Human}$.\nSince children have everything their parents have (and thus can do anything the parents can do): $$\\texttt{Human} \u0026lt;: \\texttt{Mammal}$$ $$\\texttt{Mammal} \u0026lt;: \\texttt{Animal}$$ $$- \\textit{and transitively } -$$ $$\\texttt{Human} \u0026lt;: \\texttt{Animal}$$\nGenerally:\n$$\\texttt{Child} \u0026lt;: \\texttt{Parent}$$\nThis is called width subtyping since supertypes (opposite of subtypes) contain a subset of fields (along the width of the class definition).\nUnrelated structures The notion of width subtyping can be extended to datatypes without hierarchical relationships.\nFor example, suppose there are two unrelated datatypes with the following definitions.\n$$ \\begin{align*} \u0026amp;\\texttt{struct Named:}\\newline \u0026amp;\\texttt{\\qquad string name}\\newline \u0026amp;\\newline \u0026amp;\\texttt{struct User:}\\newline \u0026amp;\\texttt{\\qquad string name}\\newline \u0026amp;\\texttt{\\qquad string age} \\end{align*} $$\nThey have no explicit relationship. However, it sort of makes sense that whenever a program expects a $\\texttt{Named}$ entity that we can pass it a $\\texttt{User}$ (since anything a $\\texttt{Named}$ has, a $\\texttt{User}$ also has).\nExample:\n$$ \\begin{align*} \u0026amp;\\texttt{func rename(Named entity, string newName):}\\newline \u0026amp;\\texttt{\\qquad entity.name = newName}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{User user = }\\lbrace\\texttt{name: \u0026ldquo;glee\u0026rdquo;, age: 1000}\\rbrace\\newline \u0026amp;\\texttt{rename(user, \u0026ldquo;not glee\u0026rdquo;)} \\end{align*} $$\nThis can get fairly messy to type check in various type systems.\nC++ has template metaprogramming (undecideable and thus limited by recursion depth) Python uses duck typing Depth Subtyping Definition Instead of subtyping at the top level, could we subtype at the field level (and thus, their fields recursively)?\n$$ \\begin{align*} \u0026amp;\\texttt{class LivingSpace:}\\newline \u0026amp;\\texttt{\\qquad Animal resident}\\newline \u0026amp;\\newline \u0026amp;\\texttt{class Studio:}\\newline \u0026amp;\\texttt{\\qquad Human resident} \u0026amp;\\end{align*} $$\nDoes $\\texttt{Studio} \u0026lt;: \\texttt{LivingSpace}$?\nNotice that these cannot have hierarchical relationships.\nIt might make sense logically that if our program requires a $\\texttt{LivingSpace}$ that we may provide it with a $\\texttt{Studio}$ since the latter can do anything the former can do (in this case, provide $\\texttt{resident.name}$).\n$$ \\begin{align*} \u0026amp;\\texttt{func owner(LivingSpace home)} \\rightarrow \\texttt{string:}\\newline \u0026amp;\\texttt{\\qquad return home.resident.name}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{Studio studio = }\\lbrace\\texttt{resident: }\\lbrace- \\textit{some human} -\\rbrace\\rbrace\\newline \u0026amp;\\texttt{print(owner(studio))} \\end{align*} $$\nCaveat $$ \\begin{align*} \u0026amp;\\texttt{func reassignResident(LivingSpace home, Animal newResident):}\\newline \u0026amp;\\texttt{\\qquad home.resident = newResident}\\newline \u0026amp;\\text{}\\newline \u0026amp;\\texttt{Studio studio = }\\lbrace\\texttt{resident: }\\lbrace- \\textit{some human} -\\rbrace\\rbrace\\newline \u0026amp;\\texttt{reassignResident(studio, }\\lbrace- \\textit{some animal } -\\rbrace) \\end{align*} $$\nAh, so here\u0026rsquo;s where it breaks down. We want to assign our subtyped field. But the true underlying structure requires more!\n$\\texttt{reassignResident}$ is under the impression that an $\\texttt{Animal}$ is enough to fill up a $\\texttt{LivingSpace}$, which is logically true. But if we pass $\\texttt{reassignResident}$ a $\\texttt{Studio}$, it should really expect a $\\texttt{Human}$ instead of an $\\texttt{Animal}$.\nIt turns out that the breakdown occurs because of aliasing. Thus, depth subtyping works with immutable structures (records).\nFunctions Introduction Functions are values. So how do we typecheck function assignment? We\u0026rsquo;ll reuse some types from above.\n$$ \\begin{align*} \u0026amp;\\texttt{Mammal} \\rightarrow \\texttt{Mammal someFunction}=\\ldots\\newline \u0026amp;\\texttt{Mammal input = }\\lbrace\\ldots\\rbrace\\newline \u0026amp;\\texttt{Mammal output = someFunction(input)} \\end{align*} $$\nThe question is: what types can we assign to $\\texttt{someFunction}$?\nOutputs Let\u0026rsquo;s trial and error, and try to reason the solution out.\n$$ \\begin{align*} \u0026amp;\\texttt{Mammal} \\rightarrow \\texttt{Human functionValue}=\\ldots\\newline \u0026amp;\\texttt{Mammal} \\rightarrow \\texttt{Mammal someFunction = functionValue} \\end{align*} $$\n$\\texttt{functionValue}$ returns a $\\texttt{Human}$. Executions of $\\texttt{someFunction}$ expect a return value that can do everything a $\\texttt{Mammal}$ can do, which a $\\texttt{Human}$ satisfies. This works.\n$$\\texttt{actualOutput} \u0026lt;: \\texttt{expectedOutput}$$\nFor sake of clarity, let\u0026rsquo;s try it the other way.\n$$ \\begin{align*} \u0026amp;\\texttt{Mammal} \\rightarrow \\texttt{Animal functionValue}=\\ldots\\newline \u0026amp;\\cancel{\\texttt{Mammal} \\rightarrow \\texttt{Mammal someFunction = functionValue}} \\end{align*} $$\nClearly, an execution to $\\texttt{someFunction}$ which expects a $\\texttt{Mammal}$ return type will miss out on the $\\texttt{furColor}$ attribute.\nInputs Again, let\u0026rsquo;s trial and error.\n$$ \\begin{align*} \u0026amp;\\texttt{Human} \\rightarrow \\texttt{Mammal functionValue}=\\ldots\\newline \u0026amp;\\cancel{\\texttt{Mammal} \\rightarrow \\texttt{Mammal someFunction = functionValue}} \\end{align*} $$\nClearly, whatever we provide as input must be able to do whatever $\\texttt{someFunction}$ requires of it. If we provide $\\texttt{Mammal}$, $\\texttt{functionValue}$ expects a $\\texttt{Human}$ which might use attributes like $\\texttt{occupation}$ which aren\u0026rsquo;t present in $\\texttt{Mammal}$.\n$$ \\begin{align*} \u0026amp;\\texttt{Animal} \\rightarrow \\texttt{Mammal functionValue}=\\ldots\\newline \u0026amp;\\texttt{Mammal} \\rightarrow \\texttt{Mammal someFunction = functionValue} \\end{align*} $$\nProviding $\\texttt{someFunction}$ with an input that can do at least what $\\texttt{Mammal}$ can do will allow it to safely be used as input to its value, $\\texttt{functionValue}$.\n$$\\texttt{expectedInput} \u0026lt;: \\texttt{actualInput}$$\nPutting it All Together It\u0026rsquo;s a little counterintuitive, but the inputs and outputs of a function subtype have opposite directionality (as we saw above).\n$$ \\begin{align*} \u0026amp;\\texttt{Animal} \\rightarrow \\texttt{Human functionValue}=\\ldots\\newline \u0026amp;\\texttt{Mammal} \\rightarrow \\texttt{Mammal someFunction = functionValue} \\end{align*} $$\n$$\\begin{align*} \\texttt{I}\u0026amp;\\texttt{\u0026rsquo;} \u0026lt;:\\texttt{I}\\newline \u0026amp;\\texttt{O} \u0026lt;:\\texttt{O\u0026rsquo;}\\newline \u0026amp;\\implies\\newline \\texttt{I}\\rightarrow\\medspace\u0026amp;\\texttt{O} \u0026lt;: \\texttt{I\u0026rsquo;}\\rightarrow\\texttt{O\u0026rsquo;} \\end{align*}$$\n","date":"2023-07-09T00:00:00Z","image":"https://kiblitz.github.io/p/subtyping/purple_hu8504565dadecf4da289ec336c8431fcf_1049097_120x120_fill_q75_box_smart1.jpg","permalink":"https://kiblitz.github.io/p/subtyping/","title":"Type Checking: Subtyping"},{"content":"Motivation A prevalent usecase of hashing is in storing sets or mappings for a subset of the input space \u0026mdash; hash tables. An optimal hash table uniformly distributes elements among its buckets.\nUniversal Hashing Definition A randomized algorithm $H$ for constructing hash functions $h:U\\rightarrow\\lbrace 0,1,\u0026hellip;,M-1\\rbrace$ is universal if $\\forall x \\neq y \\text{ s.t. } x, y\\in U$, we have $$\\mathbb{P} [h(x)=h(y)|\\thinspace h \\leftarrow H]\\leq\\frac{1}{M}$$\nConstruction Random Matrix Suppose keys are $u$-bits long and $M=2^m$. Define $A$ to be a $m$-by-$u$ matrix filled with $0$ and $1$ randomly.\nm u A x = h ( x ) = A x Claim $H=\\lbrace h\\rbrace$ is universal Proof Consider an arbitrary pair of distinct keys $x, y$. Suppose they differ in the $i$th bit. WLOG, $x_i=0$ and $y_i=1$. Observe that regardless of the elements in the $i$th column of $A$, $h(x)=Ax$ since $x_i=0$.\nHowever, each of the $2^m$ possibilities for the $i$th column of $A$ yield distinct $h(y)=Ay$. A bit flip in the $i$th column of $A$ at row $j$ flips $Ay$ at the $j$th bit\n$$\\mathbb{P} [Ax=Ay]=\\frac{1}{2^m}$$ This is unfortunately quite space inefficient.\nRandom Vector View the key $x$ as a vector of integers $\\langle x_1, x_2, \u0026hellip;, x_k \\rangle$ where $0\\leq x_i \u0026lt; M$ and $M$ is prime.\nDefine a $k$-length vector $r_1, r_2, \u0026hellip;, r_k$ filled with random values where $0\\leq r_i \u0026lt; M$.\n$$h(x)=r\\cdot x\\mod M$$\nClaim $H=\\lbrace h\\rbrace$ is universal Proof Consider an arbitrary pair of distinct keys $x, y$. Suppose they differ in the $i$th number $x_i \\neq y_i$. Consider the dot product defined by $h$ excluding the $i$th expression. Specifically,\n$$h\u0026rsquo;(x)=\\sum_{j\\neq i}r_jx_j$$ Thus, $$h(x)=h\u0026rsquo;(x)+r_ix_i$$ Collision between $x, y$ occurs precisely when $h\u0026rsquo;(x) + r_ix_i = h\u0026rsquo;(y) + r_iy_i\\mod M$. $$r_i(x_i-y_i)=h\u0026rsquo;(y)-h\u0026rsquo;(x)\\mod M$$ Note that because of $M$\u0026rsquo;s primality, every integer has a multiplicative inverse. Thus, $r_i$ is unique. $$\\mathbb{P} [h(x)=h(y)]=\\frac{1}{M}$$ Perfect Hashing Definition A hash function is perfect for a set $S, |S|=N$ if all lookups involve $\\mathcal{O}(1)$ work.\nConstruction Try 1 \u0026mdash; Quadratic Space Let $H$ be universal and $M=N^2$.\nClaim $\\mathbb{P}[\\exists\\text{ collision in $S$}]\u0026lt; \\frac{1}{2}$ Proof There are $N\\choose 2$ pairs $(x, y)$ in $S$. Each pair has at most $\\frac{1}{M}=\\frac{1}{N^2}$ collision probability by definition of universality. $\\mathbb{P}[\\exists\\text{ collision in $S$}]\\leq \\frac{N \\choose 2}{N^2}\u0026lt;\\frac{1}{2}$ Try 2 \u0026mdash; Linear Space Let $H$ be universal and $M=N$. Hash into the first layer with $N$ buckets. Each bucket maps to a secondary layer each with $C_i^2$ slots, where $C_i$ represents the number of elements that collide in the $i$th bucket of the first layer.\nN Theorem $\\mathbb{P}[\\sum_iC_i^2 \u0026gt; 4N]\u0026lt;\\frac{1}{2}$ Proof Let $I_{xy}$ be an indicator that $x,y$ collide. Observe that within any secondary layer with $C_i$ elements ($C_i^2$ slots), for any two elements $x, y$, $I_{xy}=1$ (including $I_{xx}$, this amounts to $C_i^2$). $$\\begin{align*}\\mathbb{E}[\\sum_iC_i^2]\u0026amp;=\\mathbb{E}[\\sum_x\\sum_yI_{xy}]\\newline\u0026amp;=N+\\sum_x\\sum_{y\\neq x}\\mathbb{E}[C_{xy}]\\newline\u0026amp;\\leq N+\\frac{N(N-1)}{M}\\newline\u0026amp;=N+\\frac{N(N-1)}{N}\\newline\u0026amp;\u0026lt;2N\\end{align*}$$ By Markov\u0026rsquo;s Inequality, the problem statement is proven. $$\\mathbb{P}[X\\geq a]\\leq\\frac{\\mathbb{E}[X]}{a}$$\n","date":"2023-06-22T00:00:00Z","image":"https://kiblitz.github.io/p/451-universal-and-perfect-hashing/waterfall_bridge_cave_hu31bed5500aef27fb3896f5273832a229_13876465_120x120_fill_q75_box_smart1.jpg","permalink":"https://kiblitz.github.io/p/451-universal-and-perfect-hashing/","title":"V. Universal and Perfect Hashing"},{"content":"Introduction Motivation Suppose you want to keep an ordered mapping of keys to values. If the contents are dynamic, a self-balancing tree (i.e. AVL, red-black, etc.) is desirable to allow for logarithmic modification and access operations.\nWhat if repeated access are expected? Specifically, if a value is queried several times and is located at a leaf, then each operation has $\\mathcal{O}(\\log n)$ time complexity. But we already know the value after the first query. We should be caching accesses.\nSplay Tree The splay tree is a self-balancing binary tree with the property that accesses are cached through its internal structure.\nOperations on a splay tree are approximately the same as those of other self-balancing trees: $\\mathcal{O}(\\log n)$ amortized.\nAt a high level, any operation on a node $N$ restructures the tree so that $N$ becomes the new root. Thus, repeated queries have $\\mathcal{O}(1)$ time complexity.\nDefinition Rotations There are three splay steps for moving $N$ to the root (in these cases, $x$ upwards). Each is constructed using rotations. Each of these three have a mirror version. Zig is specifically for when $x$ is the child of the root node.\nZig When $y$ is the root.\nx y = = = \u0026gt; x y Zig-zag y z x = = = \u0026gt; y x z = = = \u0026gt; y x z Zig-zig x y z = = = \u0026gt; x y z = = = \u0026gt; x y z = = = \u0026gt; The arrows above signify rotations.\nThe arrows below signify splay steps.\nRotations make up splay steps, but for analysis purposes we only care about splay steps.\nAccess Whenever we want to access (i.e. find the mapped value of) $N$, we traverse to $N$ and then splay it to the root.\nExamples 0 1 2 3 4 5 6 $\\texttt{splay}(0)$\n0 3 1 4 2 5 6 0 1 5 3 6 2 4 1 0 3 5 2 4 6 $\\texttt{splay}(3)$\n0 1 2 3 4 5 6 Analysis Setup Weights Purely for the purposes of analysis, assign each node $x$ with weight $w(x)\u0026gt;0$.\nSizes Let $T(x)$ denote the subtree rooted at node $x$. $$s(x)=\\sum_{y\\in T(x)} w(y)$$\nRank $$r(x)=\\lfloor\\log_2(s(x))\\rfloor$$ Observe that in a rotation between nodes $x,y$, the sizes (and thus ranks) of only $x,y$ change. Thus, splay steps only alter the ranks of the nodes they involve.\nPotential Let $T$ denote the entire tree state. $$\\Phi(T)=\\sum_{x\\in T}r(x)$$\nExample Let $w(\\cdot)=1$. Sizes $s(x)$ on left and ranks $r(x)$ on right.\n1 2 6 8 9 2 3 1 1 0 1 2 3 3 1 1 0 0 $$\\Phi(T)=11$$ Observe that when $w(\\cdot)=1$, $\\Phi(T)=\\mathcal{O}(n)$ when $T$ is balanced, and $\\Phi(T)=\\mathcal{O}(n\\log n)$ when $T$ is most unbalanced (long chain)\nAccess Lemma Lemma The amortized time cost for splaying node $x$ on tree $T$ with root $t$ is at most the following (regardless of $w$): $$3(r(t)-r(x))+1$$ Recall: $$ac_i = c_i + \\Phi(S_i)-\\Phi(S_{i-1})$$\nThis is a very tedious and dense proof. You\u0026rsquo;ll be fine if you take my word for it that the lemma is true.\nProof Observe that if two siblings have the same rank $r$, then their sizes are at least $2^r$. Thus, their parent has size at least $2\\cdot 2^r=2^{r+1}$. Thus, the parent node has rank at least $r+1$. Conversely, observe that if a node $x$ and its parent have the same rank $r$, then the sibling of $x$ must have rank less than $r$.\nCall this observation the Rank Rule.\nCall $T_i$ the tree state after splay step $i$, where $T_0=T$. Let $r_i(n)$ be the rank of node $n$ in $T_i$. We define $ac_i\u0026rsquo;=c_i\u0026rsquo;+\\Phi(T_i)-\\Phi(T_{i-1})$, $c_i\u0026rsquo;$ is the cost of the $i$th splay step and $ac_i\u0026rsquo;$ is the amortized cost of the $i$th splay step. Observe that a splay with $k$ splay steps is consistent with global $ac$: $$\\begin{align*}ac\u0026amp;=\\sum_iac_i\u0026rsquo;\\newline\u0026amp;=\\sum_ic_i\u0026rsquo;+(\\Phi(T_k)-\\Phi(T_{k-1}))+\u0026hellip;+(\\Phi(T_1)-\\Phi(T))\\newline\u0026amp;=c+\\Phi(T_k)-\\Phi(T)\\end{align*}$$\nFor readibility purposes, if $i$ is fixed at a proof step, we will refer to $i$ as $\\text{curr}$ and $i-1$ as $\\text{prev}$.\nWe will show that if splay step $i$ is a zig step moving node $a$ upwards to $b$: $$ac_\\text{curr}\u0026rsquo;\\leq 3(r_\\text{prev}(b)-r_\\text{prev}(a))+1$$ We will also show that if splay step $i$ is either a zig-zag or zig-zig step: $$ac_\\text{curr}\u0026rsquo;\\leq 3(r_\\text{prev}(b)-r_\\text{prev}(a))$$\nSince the zig step can occur at most once, we would be able to prove the problem statement. $$ac=\\sum_iac_i\u0026rsquo;\\leq 1 + \\underbrace{3(r(t) -r(x))}_{\\text{telescopes}}$$ Zig a b = = = \u0026gt; a b This can only occur if $b$ is the root. Since the rank on the root is constant (sum of all weights is constant): $$r_\\text{curr}(a)=r_\\text{prev}(b)$$ Since the rank of a child is at most that of its parent: $$r_\\text{curr}(b)\\leq r_\\text{curr}(a)=r_\\text{prev}(b)$$\nThe root node still has rank $r_\\text{prev}(b)$ (no change) and its child at most increases from $r_\\text{prev}(a)$ to $r_\\text{prev}(b)$.\n$$\\Phi(T_\\text{curr})-\\Phi(T_\\text{prev})\\leq r_\\text{prev}(b)-r_\\text{prev}(a)$$ $$ac \\leq 1 + r_\\text{prev}(b)-r_\\text{prev}(a)\\leq 3(r_\\text{prev}(b)-r_\\text{prev}(a))+1$$ Zig-zag c b a = = = \u0026gt; c a b = = = \u0026gt; c a b Case $r_\\text{prev}(a)=r_\\text{prev}(b)$ Since the rank of a node is lower bounded by the rank of its child, $r_\\text{prev}(c)=r_\\text{prev}(a)=r_\\text{prev}(b)$.\nRecall that since the sum of the weights of the subtree are the same, $r_\\text{prev}(b)=r_\\text{curr}(a)$. By the Rank Rule: $$r_\\text{curr}(c)\u0026lt;r_\\text{curr}(a) \\text{ OR } r_\\text{curr}(b)\u0026lt;r_\\text{curr}(a)$$ Since $r(\\cdot)$ is integral, $$r_\\text{curr}(c)\\leq r_\\text{curr}(a) - 1 \\text{ OR } r_\\text{curr}(b)\\leq r_\\text{curr}(a) - 1$$\nThus, $$\\begin{align*}\\Phi(T_\\text{curr})-\\Phi(T_\\text{prev})\u0026amp;= (r_\\text{curr}(a) + r_\\text{curr}(b) + r_\\text{curr}(c))-(r_\\text{prev}(a) + r_\\text{prev}(b) + r_\\text{prev}(c))\\newline \u0026amp;\\leq r_\\text{curr}(a) + (r_\\text{curr}(a) + r_\\text{curr}(a) - 1)-(r_\\text{curr}(a) + r_\\text{curr}(a) + r_\\text{curr}(a))\\newline \u0026amp;= -1\\end{align*}$$ $$ac \\leq 1 - 1 =0 \\leq 3(r_\\text{prev}(b)-r_\\text{prev}(a))$$ Case $r_\\text{prev}(a)\u0026lt;r_\\text{prev}(b)$ Since $r(\\cdot)$ is integral and $r_\\text{prev}(a)\u0026lt;r_\\text{prev}(b)$,\n$$r_\\text{prev}(a)+1\\leq r_\\text{prev}(b)$$\nAs before, $r_\\text{prev}(b)=r_\\text{curr}(a)$, and all node ranks are upper bounded by those of their parents.\n$$\\begin{align*}\\Phi(T_\\text{curr})-\\Phi(T_\\text{prev})\u0026amp;= (r_\\text{curr}(a) + r_\\text{curr}(b) + r_\\text{curr}(c))-(r_\\text{prev}(a) + r_\\text{prev}(b) + r_\\text{prev}(c))\\newline \u0026amp;\\leq r_\\text{prev}(b) + r_\\text{prev}(b) + r_\\text{prev}(b)-(r_\\text{prev}(a) + (r_\\text{prev}(a)+1) + r_\\text{prev}(a))\\newline \u0026amp;= 3(r_\\text{prev}(b)-r_\\text{prev}(a))-1\\end{align*}$$\n$$ac \\leq 1 + 3(r_\\text{prev}(b)-r_\\text{prev}(a))- 1 = 3(r_\\text{prev}(b)-r_\\text{prev}(a))$$ Zig-zig a c b = = = \u0026gt; a c b = = = \u0026gt; a c b Case $r_\\text{prev}(a)=r_\\text{prev}(b)$ Since the rank of a node is lower bounded by the rank of its child, $r_\\text{prev}(c)=r_\\text{prev}(a)=r_\\text{prev}(b)$.\nAs before, $r_\\text{prev}(b)=r_\\text{curr}(a)$, and all node ranks are upper bounded by those of their parents.\nLet $r_\\text{inter}(\\cdot)$ indicate node ranks in the intermediate rotation (rooted at $c$). Observe that $r_\\text{prev}(a)=r_\\text{inter}(a)$ and $r_\\text{inter}(b)=r_\\text{curr}(b)$ since their children remain the same. By the Rank Rule, $r_\\text{inter}(b) \u0026lt; r_\\text{inter}(c)=r_\\text{inter}(a)$. Because $r(\\cdot)$ is integral, $$r_\\text{curr}(b)\\leq r_\\text{curr}(a)-1$$\nThus, $$\\begin{align*}\\Phi(T_\\text{curr})-\\Phi(T_\\text{prev})\u0026amp;= (r_\\text{curr}(a) + r_\\text{curr}(b) + r_\\text{curr}(c))-(r_\\text{prev}(a) + r_\\text{prev}(b) + r_\\text{prev}(c))\\newline \u0026amp;\\leq r_\\text{curr}(a) + (r_\\text{curr}(a)-1) + r_\\text{curr}(a) - (r_\\text{curr}(a) + r_\\text{curr}(a) + r_\\text{curr}(a))\\newline \u0026amp;= -1\\end{align*}$$\n$$ac \\leq 1 - 1 =0 \\leq 3(r_\\text{prev}(b)-r_\\text{prev}(a))$$ Case $r_\\text{prev}(a)\u0026lt;r_\\text{prev}(b)$ Since $r(\\cdot)$ is integral and $r_\\text{prev}(a)\u0026lt;r_\\text{prev}(b)$,\n$$r_\\text{prev}(a)+1\\leq r_\\text{prev}(b)$$\nAs before, $r_\\text{prev}(b)=r_\\text{curr}(a)$, and all node ranks are upper bounded by those of their parents.\n$$\\begin{align*}\\Phi(T_\\text{curr})-\\Phi(T_\\text{prev})\u0026amp;= (r_\\text{curr}(a) + r_\\text{curr}(b) + r_\\text{curr}(c))-(r_\\text{prev}(a) + r_\\text{prev}(b) + r_\\text{prev}(c))\\newline \u0026amp;\\leq r_\\text{prev}(b) + r_\\text{prev}(b) + r_\\text{prev}(b)-(r_\\text{prev}(a) + (r_\\text{prev}(a)+1) + r_\\text{prev}(a))\\newline \u0026amp;= 3(r_\\text{prev}(b)-r_\\text{prev}(a))-1\\end{align*}$$\n$$ac \\leq 1 + 3(r_\\text{prev}(b)-r_\\text{prev}(a))- 1 = 3(r_\\text{prev}(b)-r_\\text{prev}(a))$$ Balance Theorem Theorem A sequence of $k$ splays in a tree of $n$ nodes has time complexity $$\\mathcal{O}(k\\log n + n\\log n)$$ Proof Set $w(\\cdot)=1$. By the Access Lemma, $$\\begin{align*}ac_i \u0026amp;= c_i + \\Phi(T_i)-\\Phi(T_{i-1}) \\newline\u0026amp;\\leq 3(r(t)-r(x) + 1\\newline\u0026amp;\\leq 3(\\log_2(n)-0)+1\\newline\u0026amp;\\leq 3\\log_2(n)+1\\end{align*}$$ Thus, $$\\sum_i ac_i = \\sum_i c_i + \\Phi(T_m)-\\Phi(T_{0}) \\leq k (3\\log_2 n + 1)$$ Since $\\log(\\cdot)\u0026gt;0$ and $r(t)\\leq\\log_2 n$, $$0\\leq \\Phi(T)\\leq n\\log_2 n$$ Thus, $$\\begin{align*}\\sum_i c_i -n \\log_2 n \u0026amp;\\leq k (3\\log_2 n + 1)\\newline\\sum_i c_i \u0026amp;\\leq n \\log_2 n + k (3\\log_2 n + 1)\\newline\u0026amp;\\in\\mathcal{O}(k\\log n + n\\log n)\\end{align*}$$ Operations Access As we mentioned before, access searches for a node $x$ then splays it if found. Since binary search has time complexity $\\mathcal{O}(\\log n)$, the work is dominated by the splaying.\nInsert First, traverse $T$ as if to search for the node $x$. Once we reach a node $n$ and cannot traverse further (i.e. $\\texttt{insert}(3)$ but the $2$ node has no right child), splay $n$.\nNow, we can insert $x$ appropriately into $T$.\nL n R = = = \u0026gt; L n x R o r L x n R Again, the search and insertion ($\\mathcal{O}(1)$) is dominated by the splaying.\nDelete First, splay the node we want to delete $x$. Now consider its children subtrees $L,R$. After removing $x$, splay the right-most node in $L$. Clearly, this new $L\u0026rsquo;$ has no right child. Set $R$ to be its new right child.\nL x R = = = \u0026gt; L R = = = \u0026gt; L ' R As before, the search is dominated by the two splaying operations.\nAbove and Beyond Static Optimality Theorem Let T be any static search tree with $n$ nodes. Let $t$ be the cost of searching for all nodes in a sequence of $s$ accesses (sum of depths of all nodes). The cost of splaying that sequence of requests, starting with any initial splay tree is $\\mathcal{O}(n^2+t)$. Can be proved with $w(x)=\\text{number of times $x$ is accessed)}$\nFor a static tree $T$, $n$ is constant. This is powerful since essentially, splay trees perform only a constant sum ($n^2$) of work worse than the most optimal tree for $s$.\nSequential Access Theorem The cost of accessing each of the $n$ nodes in a tree in in-order order is $\\mathcal{O}(n)$ ","date":"2023-06-20T00:00:00Z","image":"https://kiblitz.github.io/p/451-splay-trees/waterfall_forest_hu58107b35344101924e39ea2edc9e9f45_5735995_120x120_fill_q75_box_smart1.jpg","permalink":"https://kiblitz.github.io/p/451-splay-trees/","title":"IV. Splay Trees"},{"content":"Problem You and your friend come accross an adversary $\\mathcal{E}$ who challenges you to a game.\nOne of you will privately visit $\\mathcal{E}$ at his grand table. WLOG, let\u0026rsquo;s say it was you. There are $n$ coins that can fit in $n$ empty slots. One-by-one, $\\mathcal{E}$ will point at an empty slot and you must place a coin positioned either heads or tails on that slot. This goes on until $n-1$ slots have been filled.\nAt this point, $\\mathcal{E}$ will fill the last slot $L$ with a coin oriented at their discretion. Now, your friend will come to the grand table. It is their job to figure out which slot is $L$ without consulting you. Specifically, they must select a set of $K$ slots for which they can guarantee one of these slots is $L$.\nWhat strategy will you and your friend employ to minimize $K$?\nH T H H H T H T T T H H H H T H H H H H T T T T H H L T T H T H T T T T T H H T H H H T H H T H H T H T T T T H H H T H H T T H H Some Ideas What if we could signal to our friend what the last slot is like an airport runway?\nT T H T T T T H T T H H L H H T T H T T T T H T T The issue is, we don\u0026rsquo;t know what $L$ is ahead of time. Specifically, the last slots chosen by $\\mathcal{E}$ could all be disconnected from each other so we couldn\u0026rsquo;t coordinate the signal.\nT T T T T T T T T T T T T T T T T T T T Spoilers ahead\nSolution The trick is to force $\\mathcal{E}$ into a position where either final board state yields information.\nThe Right Direction What if we designate the first $\\frac{n}{2}$ slots to be for heads, and the rest to be for tails?\nH H H T T H H H T T H H L T T H H T T T H H T T T Whichever is the majority, we know that $L$ must be among them (in the case where $n$ is even, if we picked more heads and the final board state was split, then we know $L$ must be tails).\nThus, $K$ has approximately (rounded up) $\\frac{n}{2}$ coins.\nGrouping Pairs Here\u0026rsquo;s an idea. Make pairs of coin slots. The first chosen slot in a pair will be heads, the second tails. When $\\mathcal{E}$ picks the last orientation, one of two cases occurs.\n$\\mathcal{E}$ chooses heads. Then, one pair will have two heads so we know that it was one of these two slots. H T T H H H H T H T $\\mathcal{E}$ chooses tails. Then, all pairs will have one coin of each orientation, so we know it was one of the tails. H T T H T H H T H T In the worst case (when all groups are similar), $K$ has $\\frac{n}{2}$ coins.\nTriples Make triples of coin slots. The first two chosen slots in a triple will be heads, the last tails. When $\\mathcal{E}$ picks the last orientation, one of two cases occurs.\n$\\mathcal{E}$ chooses heads. Then, one triple will have all heads so we know that it was one of these slots. H H T H H H H T H $\\mathcal{E}$ chooses tails. Then, all triples will have one coin oriented at tails, so we know it was one of the tails. H H T H T H H T H In the worst case (when all groups are similar), $K$ has $\\frac{n}{3}$ coins.\nGeneralizing We can keep increasing group sizes at the cost of number of groups. At what group size/count is $K$ optimal?\nOnce the group size surpasses the number of groups, the worst case scenario will be when one group differs from the rest (last coin within a group is heads).\nH H H H H H H H H H H $\\min(\\text{size, count})$ is maximized when $\\text{size}=\\text{count}$. Since $\\text{size}*\\text{count}=n$, our group sizes are optimally set to $\\sqrt{n}$ (specifically, $\\lceil\\sqrt n\\rceil$). Thus, $K$ is minimized to $\\lceil\\sqrt n\\rceil$ coins.\nCeiling since if $n$ is not a perfect square, we should create groups as if it were a perfect square and blank out the nonexistent coins afterwards\nExtension Problem Suppose we play the same game, except instead of coins we play with $m$-sided dice. How does the strategy change, and how does $K$ change?\nObviously if $m=1$, then vacuously $K$ must have all $n$ dice.\n$m=2$ is just the original problem.\nIf $m\u0026gt;2$, one strategy is to use the same strategy as in $m=2$, and only utilize $2$ values of the dice. This means that optimal $K$ has at most $\\lceil\\sqrt{n}\\rceil$ dice. With one extra value, we can do better.\nSpoilers ahead\n3-sided Dice The Right Direction We need to approach this $m$-dimensionally. Intuitively, $K$ should optimally have $\\sqrt[m]{n}$, since extra orientations should correlate with axes to work with. But let\u0026rsquo;s start with a concrete example: $n=27$ and $m=3$.\nAgain, we want the last dice to shrink the \u0026ldquo;last dice space\u0026rdquo;, specifically to $3$ possibilities here. As in the original problem, perhaps we want groups to mainly consist of $1$ so that if $\\mathcal{E}$ sets the $L$ dice to $1$, we know it is in that group.\n1 1 Thinking $3$-dimensionally, what if we had $3$ groups of $3$ groups of $3$? Let\u0026rsquo;s start with just the first group of groups, or \u0026ldquo;row\u0026rdquo;.\n1 1 1 1 1 1 Suppose $L$ is part of this \u0026ldquo;row\u0026rdquo;. In other words, $L$ is one of these unfilled slots. Let\u0026rsquo;s employ the same strategy as before where the last dice of each group is oriented at $2$.\n1 1 1 2 1 1 1 2 If $L$ is set to $1$, we know it is in the first group. If $L$ is set to $2$, then we know that it is among the \u0026ldquo;$2$ dice\u0026rdquo; in this row.\nWe still have two more rows though.\n\u0026ldquo;3 dice\u0026rdquo; Advantage If we naively just use the $m=2$ strategy for all rows:\n1 2 1 1 1 1 1 2 1 2 1 2 1 1 1 1 2 1 1 1 1 2 2 2 1 1 $\\mathcal{E}$ orienting the $L$ dice to $2$ only tells us it\u0026rsquo;s one of all of the \u0026ldquo;$2$ dice\u0026rdquo; among all of the rows. It\u0026rsquo;s time to use the \u0026ldquo;3 dice\u0026rdquo;.\nFollowing the pattern, if we assign the last of every group to be $2$, what if we assign the last of every row to be $3$?\n1 2 1 1 1 1 1 3 1 2 1 2 1 1 1 1 2 1 1 1 1 3 2 2 1 1 If $L$ is assigned $1$, we know it is in the group with all $1$s If $L$ is assigned $2$, then we know it is among the $2$s in the row that doesn\u0026rsquo;t have a single $3$ If $L$ is assigned $3$, we know that it is among the $3$s across rows Thus, $K$ is minimized to $\\lceil\\sqrt[3] n\\rceil$ dice.\n4-sided Dice Extending 4-sided Dice It is difficult to imagine things with dimensionality greater than $3$. Instead, we can think about it as just extending the idea in $m=3$ with more groups of groups.\nLet $g=\\sqrt[4]{n}$ be the group size. Each row has $g^3$ dice, and there are $g$ rows. Partitioned further, each row has $g$ groups of groups, or \u0026ldquo;inner rows\u0026rdquo; each with $g$ groups of $g$ dice each. Groups are assigned $1$ until the last which is assigned $2$. Except in inner rows, where it is assigned $3$. Except in rows where it is assigned $4$.\nConcrete Example Suppose $n=16$.\n1 1 4 2 1 3 2 1 3 1 1 2 1 1 2 As before, the last of each group is assigned $2$ until it is the last of its parent group. Each of the four quadrants represents an inner row, and its last die is assigned $3$ (top right and bottom left). The rows are just rows and have its last die assigned $4$.\nIf $L$ is assigned $1$, we know it is in the group with all $1$s If $L$ is assigned $2$, we know that it is among the $2$s in the inner row with all $2$s If $L$ is assigned $3$, then we know it is among the $3$s in the row that doesn\u0026rsquo;t have a single $4$ If $L$ is assigned $4$, then we know it is among the $4$s across rows Thus, $K$ is minimized to $\\lceil\\sqrt[4] n\\rceil$ dice.\nGeneralizing We can continue to recursively create more parent groups as $m$ increases as shown above. Doing so allows us to optimize $K$ to have $\\lceil\\sqrt[m]n\\rceil$ dice.\n","date":"2023-06-16T00:00:00Z","image":"https://kiblitz.github.io/p/last-coin/coin_hu99a99619cf846da61b8b61e69965a107_1295210_120x120_fill_q75_box_smart1.jpeg","permalink":"https://kiblitz.github.io/p/last-coin/","title":"Last Coin"},{"content":"Introduction Motivation Analyzing an algorithm\u0026rsquo;s worst-case time complexity can be too pessimistic. Perhaps an algorithm $\\mathcal{A}$ is usually cheap, but every $n$ executions, it is expensive. Should $\\mathcal{A}$ be categorized as an expensive algorithm?\nDefinition The amortized time cost for $\\mathcal{A}$ is the average time cost per execution across any sequence of executions of length $n$ for some determined $n$.\n$n=1$ is worst-case analysis, but larger $n$ can offer more optimistic analysis\nExamples Binary Counter Problem We want to store a big binary counter in an array $A$ initialized to $0$. The cost model is every bit flip.\n$$ \\begin {array}{ccccc|c} \\underline{A_4}\\quad \u0026amp; \\underline{A_3}\\quad \u0026amp; \\underline{A_2}\\quad \u0026amp; \\underline{A_1}\\quad \u0026amp; \\underline{A_0}\\quad \u0026amp; \\quad\\underline{\\textbf{cost}} \\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad1\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad2\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad1\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; 1\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad3\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad1\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 1\\quad \u0026amp; 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad2\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 1\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad1\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 1\\quad \u0026amp; 1\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad4\\newline 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad1\\newline 0\\quad \u0026amp; 1\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\end {array}$$\nThe worst-case time complexity is $\\mathcal{O}(\\log n)$ since at worst $n$ becomes a power of $2$, and we have to flip all of its significant bits.\nAmortized Analysis Theorem The amortized time cost is at most $2$. Proof Consider $n$ (for large $n$) executions beginning at any state. $A_0$ flips every execution. $A_1$ flips every other execution. $A_2$ flips every 4 executions. $A_k$ flips every $2^k$ executions. The total cost is the sum of these flips.\n$$n + \\frac{n}{2} + \\frac{n}{4} + \u0026hellip; \\leq 2n$$ Thus, the average per execution is at most $2\\in\\mathcal{O}(1)$. The \u0026ldquo;beginning at any state\u0026rdquo; is important. Otherwise, our analysis is not generalizable.\nExpensive Binary Counter Problem We want to store a big binary counter in an array $A$ initialized to $0$. It costs $2^k$ to flip bit $A_k$.\nSame problem but with exponential costs\n$$ \\begin {array}{ccccc|c} \\underline{A_4}\\quad \u0026amp; \\underline{A_3}\\quad \u0026amp; \\underline{A_2}\\quad \u0026amp; \\underline{A_1}\\quad \u0026amp; \\underline{A_0}\\quad \u0026amp; \\quad\\underline{\\textbf{cost}} \\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad1\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad3\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad1\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; 1\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad7\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad1\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 1\\quad \u0026amp; 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad3\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 1\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad1\\newline 0\\quad \u0026amp; 0\\quad \u0026amp; 1\\quad \u0026amp; 1\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad15\\newline 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\boxed{0}\\quad \u0026amp; \\newline \u0026amp; \u0026amp; \u0026amp; \u0026amp; \u0026amp; \\quad1\\newline 0\\quad \u0026amp; 1\\quad \u0026amp; 0\\quad \u0026amp; 0\\quad \u0026amp; \\boxed{1}\\quad \u0026amp; \\end {array}$$\nThe worst-case time complexity is $\\mathcal{O}(n)$ since at worst $n$ becomes a power of $2$, and we have to flip all of its significant bits ($1+2+4+\u0026hellip;+\\frac{n}{2}+n\\leq2n$).\nAmortized Analysis Theorem The amortized time cost is at most $\\log_2 (n) + 1$. Proof Consider $n$ (for large $n$) executions beginning at any state. $A_0$ flips every execution for a cost of $1$. $A_1$ flips every other execution for a cost of $2$. $A_2$ flips every 4 executions for a cost of $4$. $A_k$ flips every $2^k$ executions for a cost of $2^k$. $n$ has $\\lfloor\\log_2 n + 1\\rfloor$ significant bits.\nThe total cost is the sum of these flips.\n$$\\underbrace{n + 2\\cdot\\frac{n}{2} + 4\\cdot\\frac{n}{4} + \u0026hellip;}_{\\lfloor\\log_2 n + 1\\rfloor} = n\\lfloor\\log_2 n + 1\\rfloor$$ Thus, the average per execution is $\\lfloor\\log_2 n + 1\\rfloor\\in\\mathcal{O}(\\log n)$. Unbounded Array Problem We want to store a linear stream of data. We start with an Array $\\mathcal{A}$ of memory space of size $1$. Every new append inserts into $\\mathcal{A}$. If an append is attempted when $\\mathcal{A}$ is completely filled, we must reallocate memory at double the size and re-insert previous data before inserting the new data.\nIt costs $1$ to insert one slot of data.\n$$ \\begin {array}{c|c} \\underline{A} \u0026amp; \\underline{\\textbf{cost}} \\newline \\Box\u0026amp;\\newline \u0026amp;1\\newline \\blacksquare\u0026amp;\\newline \u0026amp;2\\newline \\blacksquare\\blacksquare\u0026amp;\\newline \u0026amp;3\\newline \\Box\\blacksquare\\blacksquare\\blacksquare\u0026amp;\\newline \u0026amp;1\\newline \\blacksquare\\blacksquare\\blacksquare\\blacksquare\u0026amp;\\newline \u0026amp;5\\newline \\Box\\Box\\Box\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\u0026amp;\\newline \u0026amp;1\\newline \\Box\\Box\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\u0026amp;\\newline \u0026amp;1\\newline \\Box\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\u0026amp;\\newline \u0026amp;1\\newline \\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\u0026amp;\\newline \u0026amp;9\\newline \\Box\\Box\\Box\\Box\\Box\\Box\\Box\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\\blacksquare\u0026amp;\\newline \\end {array}$$\nThe worst-case time complexity is $\\mathcal{O}(n)$ with respect to the data size since at worst, we are in a reallocation step where we must re-insert all old data.\nAmortized Analysis Theorem The amortized time cost is at most $3$. Proof Consider $n$ (for large $n$) executions beginning at any state. Without including the cost of inserting old data, every append costs exactly $1$. In total, this has cost $n$. Inserting old data costs the size of the old array. In total, this costs at most $n + \\frac{n}{2} + \u0026hellip; \\leq 2n$.\nThus, the total cost is at most $n+2n=3n$ and the average cost per execution is $3$.\nPotentials Potentials offer a more rigorous approach to amortized analysis. What we\u0026rsquo;ve been doing is still entirely correct, but might be problematically difficult with more complex algorithms.\nIntuition: Banker\u0026rsquo;s Method The intuitive way to think about potentials is with a bank. Every time $\\mathcal{A}$ is executed, we earn some amount of coins $k(S)$ (function on data-structure state). If the current $\\mathcal{A}$ operation is cheap, we can split our earnings between this operation and saving it in the bank. If the current $\\mathcal{A}$ operation is expensive, we can use our funds from the bank to support it.\n$k(S)$ is an amoritized time bound on $\\mathcal{A}$ if we will always have enough coins to pay for an operation at any given time.\nDefinition The potential function $\\Phi$ is a function mapping data-structure states to $\\reals$. It represents the \u0026ldquo;potential\u0026rdquo; of that state (the coin cost).\nLet $ac_i$ represent the amortized cost over $i$ algorithm executions. Let $c_i$ be the cost of the $i$th execution, and let $S_i$ being the resulting state.\n$$ac_i = c_i + \\Phi(S_i)-\\Phi(S_{i-1})$$ Analogically, $\\text{amortized cost}=\\text{actual cost}+\\text{change in potential}$.\n$$\\begin{align*}\\sum_iac_i\u0026amp;=\\sum_i(c_i+\\Phi(S_i)-\\Phi(S_{i-1}))\\newline\u0026amp;=\\sum_ic_i+\\Phi(S_n)-\\Phi(S_0)\\end{align*}$$\nObserve that if $\\Phi(S_n)\\geq\\Phi(S_0)$ (which is frequently the case): $$\\sum_ic_i\\leq\\sum_iac_i$$\nNote that $\\Phi(S)$ can be defined in any way, but unless $\\Phi(S_0)-\\Phi(S_n)$ is appropriately bounded (as in above), our determined $ac$ has no meaning.\nRevisiting Binary Counter Theorem The amortized time cost is at most $2$. Proof Let $\\Phi(S)=1\\text{s in }S$. Consider the $i$th execution $i-1\\rightarrow i$. Let $k$ be the number of carries that occur. In $10100\\rightarrow 10101$, $\\thickspace k=0$\nIn $10111\\rightarrow 11000$, $\\thickspace k=3$\n$\\Phi(S_i)-\\Phi(S_{i-1})=-k+1$ since $k$ $1$s become $0$ and one $0$ becomes a $1$. For the same reason, $c_i=k+1$. In $10100\\rightarrow 10101$\ncosts $1$ changes potential from $2\\rightarrow 3$ In $10111\\rightarrow 11000$, $\\thickspace k=3$\ncosts $4$ changes potential from $4\\rightarrow 2$ Thus, $ac_i=(k+1)+(-k+1)=2$. Since $\\Phi(S_n)\\geq\\Phi(S_0)\\thickspace\\forall n$,\n$$\\sum_ic_i\\leq\\sum_iac_i$$ ","date":"2023-06-15T00:00:00Z","image":"https://kiblitz.github.io/p/451-amortized-analysis/waterfall_forest_pool_hu4175320c3e1c0627b37f06fe8d92c9ae_1745274_120x120_fill_q75_box_smart1.jpg","permalink":"https://kiblitz.github.io/p/451-amortized-analysis/","title":"III. Amortized Analysis"},{"content":"Problem We know that the unique edge in quantum computing is derived from negative amplitudes. How can we cause a qubit value to have negative amplitude?\nSolution Working with the Hadamard Gate The only instruction that we\u0026rsquo;ve seen that introduces negative amplitude is the hadamard gate. Specifically, $1\\xmapsto{-1} 1$.\n$$H=\\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \u0026amp; 1 \\newline 1 \u0026amp; -1\\end{bmatrix}$$\nSo if we want to enter minus world, we probably want to perform $\\texttt{HAD}$ on a qubit with value $1$.\n$$\\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \u0026amp; 1 \\newline 1 \u0026amp; -1\\end{bmatrix}\\cdot\\begin{bmatrix}0 \\newline 1\\end{bmatrix} = \\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \\newline -1\\end{bmatrix}$$\nRecall that $\\texttt{HAD}$ is its own reverse ($\\texttt{HAD}^\\dagger=\\texttt{HAD}\\implies H^2=I$). $$\\begin{align*}(\\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \u0026amp; 1 \\newline 1 \u0026amp; -1\\end{bmatrix})^\\dagger\\cdot \\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \u0026amp; 1 \\newline 1 \u0026amp; -1\\end{bmatrix}\\cdot\\begin{bmatrix}0 \\newline 1\\end{bmatrix} \u0026amp;= (\\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \u0026amp; 1 \\newline 1 \u0026amp; -1\\end{bmatrix})^\\dagger\\cdot\\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \\newline -1\\end{bmatrix}\\newline \\begin{bmatrix}0 \\newline 1\\end{bmatrix} \u0026amp;= \\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \u0026amp; 1 \\newline 1 \u0026amp; -1\\end{bmatrix}\\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \\newline -1\\end{bmatrix}\\end{align*}$$\nThe Magic The left side of the above equation shows a qubit with amplitude $1$ on value $1$. Looking at the computations in matrix form, it is clear that what we want is to somehow negate both sides of the equation.\nHere is a simple equality.\n$$-\\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \\newline -1\\end{bmatrix}=\\frac{\\sqrt{2}}{2}\\begin{bmatrix}-1 \\newline 1\\end{bmatrix}$$\nNow the solution is clear. $$\\texttt{NOT}(\\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \\newline -1\\end{bmatrix})=\\frac{\\sqrt{2}}{2}\\begin{bmatrix}-1 \\newline 1\\end{bmatrix}=-\\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \\newline -1\\end{bmatrix}$$\nPutting it All Together The first step, we applied $\\texttt{HAD}$ on a qubit with amplitude $1$ on value $1$ to get the following state. $$\\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \\newline -1\\end{bmatrix}$$ In the next step, we negated this expression with a $\\texttt{NOT}$ operation. $$\\frac{\\sqrt{2}}{2}\\begin{bmatrix}-1 \\newline 1\\end{bmatrix}$$ Finally, we applied $\\texttt{HAD}$ on this updated qubit. $$\\begin{bmatrix}0 \\newline -1\\end{bmatrix}$$\nNotice that we require in the first step for the qubit to have value $1$. If it had value $0$, the steps would be the same but without the minus sign. In other words, no effect would take place.\nThis is powerful, because now we have a $\\texttt{If }A\\texttt{=1 THEN MINUS}(A)$ subroutine.\nQuantum Code $ \\texttt{INIT}(A) \\newline\\texttt{NOT}(A) \\newline\\quad\\newline \\newline\\texttt{HAD}(A) \\newline\\texttt{NOT}(A) \\newline\\texttt{HAD}(A) $\nA 0 N O 1 T ( A 1 ) - 1 H 1 A D ( A ) 0 1 N O 1 T 1 ( A ) 1 0 H A - D 1 1 ( 1 1 A ) 0 1 0 1 $ \\mathbb{A}[0] = (1\\times 1\\times 1\\times 1) + (1\\times -1\\times 1\\times 1) = 0\\newline \\mathbb{A}[1] = (1\\times 1\\times 1\\times -1) + (1\\times -1\\times 1\\times 1) = -2 $ Unnormalized. Clearly when normalized, $\\mathbb{A}[1]=-1$.\nNew Power Suppose we created some subroutine $\\texttt{MAJ}(ABCM)$ which negates $M$ if the majority value in $ABC$ is $1$ (we will use it with $M=0$, so essentially this function just sets $M$ to the majority value).\nNow, with our new code, the following subroutine is possible.\n$ \\texttt{INIT}(ABCM) \\newline\\texttt{// assign }ABC \\newline\\texttt{MAJ}(ABCM) \\newline\\texttt{HAD}(M) \\newline\\texttt{NOT}(M) \\newline\\texttt{HAD}(M) $\nGoing forward, we can just execute subroutines like this with $\\texttt{IF MAJ}(ABCM)\\texttt{ THEN MINUS}(M)$.\n","date":"2023-06-13T00:00:00Z","image":"https://kiblitz.github.io/p/minus-world/mountain_colorful_horizon_huf999eca1e19e8beb20013b52547a3da2_1710672_120x120_fill_q75_box_smart1.jpg","permalink":"https://kiblitz.github.io/p/minus-world/","title":"IV. Minus World"},{"content":"Motivation Example Suppose we had the following quantum code.\n$\\texttt{INIT}(A)\\newline\\texttt{HAD}(A)\\newline\\texttt{HAD}(A)$\n0 1 0 0 1 1 0 0 1 1 1 - 1 1 We can see that the amplitudes on the paths to value $1$ cancel out, leaving $A=0$ with probability $1$.\nWhat happens when we throw a random qubit into the program?\nCorrectness Bug $\\texttt{INIT}(A,B)\\newline\\texttt{HAD}(A)\\newline\\texttt{CNOT}(AB)\\newline\\texttt{HAD}(A)$\n0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 1 1 1 1 0 1 - 1 1 1 Now that $B$ has a value, amplitude cancellations don\u0026rsquo;t work anymore. We don\u0026rsquo;t modify $A$ at all with this change. Yet, $A=0$ and $A=1$ each have probability $0.5$.\nThis example is a bit contrived, but you can imagine that you might need to introduce extra temporary qubits and perform computations on them like you would temporary variables in classical computing. These types of qubits are called garbage qubits.\nTaking Out the Trash So here\u0026rsquo;s the fix. Just set all the garbage qubits to $0$. That way all leaves have the same garbage qubit values and interference works as if they didn\u0026rsquo;t exist.\nThe catch? Remember that all quantum computation must be reversible. Assignment isn\u0026rsquo;t reversible. We can\u0026rsquo;t actually just set qubits to $0$.\nReversible Computation Instead, we can perform computations with our garbage qubits, use their outcomes, and then perform reversed computations on the garbage qubits.\nExample $\\texttt{INIT}(A,B)\\newline\\texttt{HAD}(A)\\newline\\texttt{CNOT}(AB)\\newline\\boxed{\\texttt{CNOT}(AB)}\\newline\\texttt{HAD}(A)$\nAgain, this example is a bit contrived. But the idea is still applicable. Once you are finished working with garbage qubits, you need to apply the inverse of the computations on those qubits so they can be reversed to $0$.\nReversal example\n$ \\texttt{CCNOT}(ABC) \\newline\\texttt{NOT}(A) \\newline\\texttt{CNOT}(AB) \\newline\\quad\\newline \\newline\\texttt{CNOT}(AB) \\newline\\texttt{NOT}(A) \\newline\\texttt{CCNOT}(ABC) $\nHadamard Recall that Hadamard performs the following mapping on qubit values. $$\\begin{align*}0\u0026amp;\\xmapsto{1}1\\newline0\u0026amp;\\xmapsto{1}0\\end{align*}$$$$\\begin{align*}1\u0026amp;\\xmapsto{1}0\\newline1\u0026amp;\\xmapsto{-1}1\\newline\\end{align*}$$ Notice that if we flip the arrows, the operation is the same. Thus, $\\texttt{HAD}$ is its own reverse. This explains why executing $\\texttt{HAD}$ twice has no effect\nTechnically this reverse operation is called dagger (will be covered in a later post).\n","date":"2023-06-12T00:00:00Z","image":"https://kiblitz.github.io/p/garbage-qubit-disposal/mountain_contrast_hub2e202448bf26b0e856d5bf940d8decf_4938325_120x120_fill_q75_box_smart1.jpg","permalink":"https://kiblitz.github.io/p/garbage-qubit-disposal/","title":"III. Garbage Qubit Disposal"},{"content":"This post has been heavily modularized so you can follow step-by-step to try to solve the puzzle.\nProblem A crew of $100$ pirates have found treasure: $100$ gold doubloons. They need to figure out a way to distribute the treasure amongst themselves.\nG G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G Specifically, there is a linear chain of command that is publically known, and at the top of the chain is the pirate captain. The captain is the one who proposes the treasure distribution. Let\u0026rsquo;s say we label every pirate with a number corresponding to chain power. $$ c\\rightarrow 99 \\rightarrow 98 \\rightarrow 97 \\rightarrow \u0026hellip; \\rightarrow 4 \\rightarrow 3 \\rightarrow 2 \\rightarrow 1$$ The pirates then simultaneously say \u0026ldquo;aye!\u0026rdquo; (including the captain) if they agree with the proposal. If at least half of the pirates say \u0026ldquo;aye!\u0026rdquo;, then it is realized. Otherwise, the captain walks the plank, and the next in command becomes captain! $$ c\\rightarrow 98 \\rightarrow 97 \\rightarrow \u0026hellip; \\rightarrow 4 \\rightarrow 3 \\rightarrow 2 \\rightarrow 1$$ What influences a pirate\u0026rsquo;s vote?\nPirates are trying to maximize their own loot In the case where a vote does not affect their rewards, pirates are ruthless and won\u0026rsquo;t say \u0026ldquo;aye!\u0026rdquo; So, how should the captain distribute the doubloons?\nSome Ideas Well, there are $100$ pirates splitting $100$ gold doubloons. Maybe the captain should $1$ to each pirate?\nBut the captain really only needs half of the votes. How about $2$ to $50$ of them?\nThere\u0026rsquo;s also a chain of command\u0026hellip; the pirates way down the hierarchy have no power right? Can the captain afford to give less doubloons to those pirates while still keeping their vote?\nClearly, there\u0026rsquo;s a optimal strategy for the captain to maximize their own loot, otherwise it wouldn\u0026rsquo;t make for a interesting puzzle.\nSpoilers ahead\nThinking with Small Numbers $100$ is a bit big to think about all of the possibilities. What if we were dealing with less pirates?\nBaby Steps Let\u0026rsquo;s start at the top and put ourselves in the captain\u0026rsquo;s shoes. $1$ pirate. Clearly with no one to make us walk the plank, we should give ourselves all $100$ doubloons!\nHow about $2$ pirates? As long as we say \u0026ldquo;aye!\u0026rdquo;, the second-in-command will never get enough votes. Again, we get all $100$ doubloons.\nOk, what about $3$ pirates? Now we are in danger, since there are enough pirates for a mutiny. We should entice one of them with some of the loot. But which one? And with how much? $$c\\rightarrow 2 \\rightarrow 1$$\nBuying Votes Let\u0026rsquo;s remember the pirate code.\nPirates are trying to maximize their own loot In the case where a vote does not affect their rewards, pirates are ruthless and won\u0026rsquo;t say \u0026ldquo;aye!\u0026rdquo; Here\u0026rsquo;s an observation. If we walk the plank, pirate $2$ becomes the new captain. How much would they get if this scenario happens?\n$$2 \\rightarrow 1$$ Doesn\u0026rsquo;t this look familiar? It\u0026rsquo;s the same case that we looked at before! Pirate $2$ will get all the doubloons here! $$2[100] \\rightarrow 1[0]$$\nSo, pirate $2$ will always vote to kill and try to be captain no matter what! Even if we as captain gave all the doubloons to pirate $2$, the pirate code states that pirates are ruthless! It follows that no matter the number of alive pirates in the crew, the relative second-in-command will always vote to kill if they want to be captain.\nClearly pirate $1$ is who we should be paying. How much should we spend?\nLet\u0026rsquo;s think back to the scenario where pirate $2$ becomes captain. $$2[100] \\rightarrow 1[0]$$ Pirate $1$ isn\u0026rsquo;t getting anything here! So, pirate $1$ really doesn\u0026rsquo;t want pirate $2$ to be captain!\nCan we be greedy and not give anything to pirate $1$? Well, remember the pirate code. $0=0$, so we\u0026rsquo;re walking the plank. But $1\u0026gt;0$! $$c[99] \\rightarrow 2[0] \\rightarrow 1[1]$$\nLess Baby Steps What about with $4$ pirates? $$c\\rightarrow 3 \\rightarrow 2 \\rightarrow 1$$ Applying our logic from before, pirate $3$ is getting $99$ doubloons if they get to be captain. If we want to buy their vote, we need to give them $100$ doubloons. $$c[0]\\rightarrow 3[100] \\rightarrow 2[0] \\rightarrow 1[0]$$ And we have $2$ votes: ourselves and pirate $3$. But this is kind of silly.\nOk, again using our logic from before, pirate $2$ will be sad and poor if pirate $3$ becomes captain. The solution follows naturally. $$c[99]\\rightarrow 3[0] \\rightarrow 2[1] \\rightarrow 1[0]$$\nGeneralizing the Approach Solving the Problem Looks like an alternating pattern. This happens because all the pirates who will get $0$ if the captain gets thrown overboard can be incentivized with $1$ doubloon. And since that makes up half of the crew, the captain can just give everyone else nothing! $$ c[51]\\rightarrow 99[0] \\rightarrow 98[1] \\rightarrow 97[0] \\rightarrow \u0026hellip; \\rightarrow 4[1] \\rightarrow 3[0] \\rightarrow 2[1] \\rightarrow 1[0]$$ This is a tight upper bound on the captain\u0026rsquo;s rewards. The crew is distributed $49$ doubloons. This is exactly the number of \u0026ldquo;ayes!\u0026rdquo; the captain needs (not including themselves) to not walk the plank.\nMore Generalization The captain has earned a hefty sum. That means there\u0026rsquo;s still space for more pirates!\nIt\u0026rsquo;s clear that we can keep this alternating pattern all the up to $200$ pirates. $$ c[1]\\rightarrow 199[0] \\rightarrow 198[1] \\rightarrow 197[0] \\rightarrow \u0026hellip; \\rightarrow 4[1] \\rightarrow 3[0] \\rightarrow 2[1] \\rightarrow 1[0]$$ The natural follow up is: what happens after $200$ pirates? Spoilers ahead\nToo Many Pirates One Step at a Time What happens when there are $201$ pirates? We are $1$ doubloon short if we try to use our normal strategy.\nNotice that, not including ourselves, we need $100$ votes. If we can\u0026rsquo;t incentivize $100$ other pirates, then it\u0026rsquo;s plank time.\nNow it\u0026rsquo;s obvious what the strategy should be.\n$$ c[0]\\rightarrow 200[0] \\rightarrow 199[1] \\rightarrow 198[0] \\rightarrow \u0026hellip; \\rightarrow 4[0] \\rightarrow 3[1] \\rightarrow 2[0] \\rightarrow 1[1]$$\nOk, so we\u0026rsquo;re a little sad that we don\u0026rsquo;t get any of the loot. But we\u0026rsquo;re not as sad as we would be if we lost this vote.\nIt\u0026rsquo;s clear that we can use the same strategy for when there are $202$ pirates.\n$$ c[0]\\rightarrow 201[0] \\rightarrow 200[1] \\rightarrow 199[0] \\rightarrow \u0026hellip; \\rightarrow 4[1] \\rightarrow 3[0] \\rightarrow 2[1] \\rightarrow 1[0]$$\n203 Pirates Ok, now what?\nWe need $101$ other pirates to say \u0026ldquo;aye!\u0026rdquo; but we only have $100$ doubloons to reward. Furthermore, there are $101$ pirates in the previous case that were not awarded any doubloons, which means that unless they are motivated to do so, they will vote to kill.\nDoes this mean that with $203$ pirates, we are doomed to walk the plank?\nUnfortunately so. Hopefully we can wash upon an island and join another band of pirates.\nSo that means that with more than $202$ pirates, the captain is always destined to die right? Spoilers ahead\n204 Pirates Déjà Vu? The argument in the previous case for our imminent death was that we needed $101$ other votes but could only buy $100$ of them. Again, we need $101$ other votes here. Isn\u0026rsquo;t it the same case now?\nHere\u0026rsquo;s a hint. There is one pirate that doesn\u0026rsquo;t require monetary motivation.\nAnother Motivator Here is a proposed rewards distribution.\n$$ c[0]\\rightarrow 203[0] \\rightarrow 202[0] \\rightarrow 201[0] \\rightarrow 200[0] \\rightarrow 199[1] \\rightarrow \u0026hellip; \\rightarrow 4[0] \\rightarrow 3[1] \\rightarrow 2[0] \\rightarrow 1[1]$$\nAs always, we get our $100$ \u0026ldquo;ayes!\u0026rdquo; from the last $200$ pirates. We get $1$ \u0026ldquo;aye!\u0026rdquo; from ourselves. Who else is on our side amongst pirates $201,202,203$?\nTurns out death is a strong motivator. Remember, if $203$ becomes captain, they will walk the plank! So pirate $203$ will also say \u0026ldquo;aye!\u0026rdquo;.\nGeneralizing the New Strategy It is the case that we will always distribute the coins amongst pirates $1$ through $200$ to get our first $100$ votes. Thus for our analysis, it is sufficient to just look at pirates $201$ onwards. $$\\boxed{201}\\boxed{202}\\xcancel{\\boxed{203}}\\boxed{204}$$\n205 Pirates For sure, we are not getting pirate $204$\u0026rsquo;s \u0026ldquo;aye!\u0026rdquo; as they won\u0026rsquo;t be sad as captain. And pirate $203$ also won\u0026rsquo;t be sad if $204$ is captain. Pirates $201$ and $202$ are not on the chopping block, so we are not getting their votes either. $$\\boxed{201}\\boxed{202}\\xcancel{\\boxed{203}}\\boxed{204}\\xcancel{\\boxed{205}}$$\n206 Pirates Using the logic from the previous case, pirates $201$ through $204$ won\u0026rsquo;t be sad if pirate $205$ becomes captain. The only pirate that will be sad is pirate $205$. So we get their vote! $$201,202,203,204\\quad\u0026mdash;\\quad \\underbrace{205, 206}_\\text{aye!}$$ Darn, still walking the plank.\n207 Pirates $$201,202,203,204\\quad\u0026mdash;\\quad \\underbrace{205, 206, 207}_\\text{aye!}$$\n208 Pirates $$201,202,203,204\\quad\u0026mdash;\\quad \\underbrace{205, 206, 207, 208}_\\text{aye!}$$ Wow! We\u0026rsquo;ve survived!\nUnfortunately for the captains in the next few cases, since pirates $205$ through $208$ are not sad with $208$ being captain, they will not be saying \u0026ldquo;aye!\u0026rdquo;.\n216 Pirates $$\\begin{matrix} 201,202,203,204,\\newline 205,206,207,208\\thickspace \\end{matrix} \\quad\u0026mdash;\\quad \\underbrace{ \\begin{matrix} 209,210,211,212, \\newline 213,214,215,216\\thickspace \\end{matrix} }_\\text{aye!}$$\nAnother surviving captain! Now the idea is clear. Every surviving captain creates a \u0026ldquo;sink state\u0026rdquo; where every pirate up to that point will never say \u0026ldquo;aye!\u0026rdquo; ever again (since they are not sad if they end up in that state). Every next surviving captain must have double the number of pirates labelled after $200$ in order to tie with these no-\u0026ldquo;aye!\u0026rdquo; pirates.\nThus, a pirate captain only survives if they are a power of $2$ after $200$. $$201, 202, 204, 208, 216, 232, 264, \u0026hellip;$$\n","date":"2023-06-11T00:00:00Z","image":"https://kiblitz.github.io/p/pirates/storm_seas_ship_huf878354edcfc18eaa884ec13bfc49714_3296843_120x120_fill_q75_box_smart1.jpg","permalink":"https://kiblitz.github.io/p/pirates/","title":"Pirates!"},{"content":"Qubit System Representations Single Qubit Recap Previously, we saw that a single qubit can be represented as a pair of amplitudes. $$A=\\begin{bmatrix} v_0 \\newline v_1 \\end{bmatrix}$$ $$\\text{OR}$$ $$A=v_0|0\\rangle + v_1|1\\rangle$$ Where $v_0$ represents $A$\u0026rsquo;s amplitude on $0$ and $v_1$ represents $A$\u0026rsquo;s amplitude on $1$.\nExtending to Multi-Qubit States In $q$-qubit systems, the representing vectors are $2^q$-dimensional where each component\u0026rsquo;s magnitude represents the amplitude on a specific value. The mapping of axis to value follows from the tensor product order. Suppose $AB$ had the following state. $$AB=v_{00}|00\\rangle + v_{01}|01\\rangle + v_{10}|10\\rangle + v_{11}|11\\rangle$$ The corresponding vector would be the following. $$AB=\\begin{bmatrix} v_{00} \\newline v_{01} \\newline v_{10} \\newline v_{11} \\end{bmatrix}$$\nClassical Quantum Gates With the exception of qubit initialization, quantum computing operations are all bijective modifications on their input qubits with no outputs. The reason for this strict rule is for computational reversibility which is essential for taking out the garbage (to be explained in a later post).\nThis is why qubit value assignment isn\u0026rsquo;t possible. It is not possible to reverse the assigned value $o$ since every possible input $i$ maps to $o$.\nDefinitions Initialize $\\texttt{INIT}(A)$\nCreates a new qubit $A$ with full amplitude on value $0$.\n$$\\begin{bmatrix} 1 \\newline 0 \\end{bmatrix}$$\nNot $\\texttt{NOT}(A)$\nNegates $A$. In other words, adds $1$ to qubit $A$ ($\\bmod\\thickspace2$).\n$$\\begin{bmatrix} 0 \u0026amp; 1 \\newline 1 \u0026amp; 0 \\end{bmatrix}$$\nControlled Not $\\texttt{CNOT}(AB)$\nIf $A=1$ then negates $B$. In other words, adds $A$ to qubit $B$ ($\\bmod\\thickspace2$).\n$$\\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\newline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0\\end{bmatrix}$$\n$$ \\begin{array}{c|c} AB \u0026amp; \\texttt{CNOT}(AB) \\newline 00 \u0026amp; 00 \\newline 01 \u0026amp; 01 \\newline \\boxed{10} \u0026amp; 11 \\newline \\boxed{11} \u0026amp; 10 \\end{array} $$\nControlled Controlled Not $\\texttt{CCNOT}(ABC)$\nIf $A=1$ and $B=1$ then negates $C$. In other words, adds $A\\And B$ to qubit $C$ ($\\bmod\\thickspace 2$).\n$$\\begin{bmatrix} 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \u0026amp; 0 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\newline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 0 \\end{bmatrix}$$\n$$ \\begin{array}{c|c} ABC \u0026amp; \\texttt{CCNOT}(ABC) \\newline 000 \u0026amp; 000 \\newline 001 \u0026amp; 001 \\newline 010 \u0026amp; 010 \\newline 011 \u0026amp; 011 \\newline 100 \u0026amp; 100 \\newline 101 \u0026amp; 101 \\newline \\boxed{110} \u0026amp; 111 \\newline \\boxed{111} \u0026amp; 110 \\end{array} $$\nSyntactic Sugar Sometimes we will define/use a subroutine $F(X_1X_2\u0026hellip;X_n)$ that outputs a value which we later execute in some pseudocode fashion (i.e. $\\text{If }F(AB)\\text{ Then}\u0026hellip;$). But technically returning a value isn\u0026rsquo;t allowed.\nThis is just syntactic sugar for creating a temporary qubit $T$ and applying $F$\u0026rsquo;s logic to modify $T$ as the output. $$\\texttt{INIT}(T)\\newline \u0026hellip;\\newline \\text{// Apply $F$ logic onto $T$}\\newline \u0026hellip; \\newline\\text{If }T\\text{ Then}\u0026hellip;$$\nAlso note that since quantum computation must be reversible, branching must be done intelligently. For example, $\\text{If}$ branches are syntactic sugar for controlled operations ($\\texttt{CTRUEBRANCH}(T\u0026hellip;)$).\nExample for negation of adding $\\texttt{CCNOT}$ to input. $$ \\begin{array}{c|c} \\text{compiled} \u0026amp; \\text{syntactic sugar} \\newline\\newline \\texttt{INIT}(A) \u0026amp; \\texttt{INIT}(A) \\newline \\texttt{INIT}(B) \u0026amp; \\texttt{INIT}(B) \\newline \\texttt{INIT}(C) \u0026amp; \\texttt{INIT}(C) \\newline \\texttt{INIT}(D) \u0026amp; \\texttt{INIT}(D) \\newline \\texttt{INIT}(T_1) \u0026amp; \\newline \\texttt{INIT}(T_2) \u0026amp; \\newline \u0026amp; \\texttt{def F}(X_1X_2)\\lbrace \\newline \u0026amp; \\texttt{INIT}(T) \\newline \u0026amp; \\texttt{NOT}(X_1) \\newline \u0026amp; \\texttt{NOT}(X_2) \\newline \u0026amp; \\texttt{CCNOT}(X_1X_2T) \\newline \u0026amp; \\texttt{NOT}(X_1) \\newline \u0026amp; \\texttt{NOT}(X_2) \\newline \u0026amp; \\texttt{Output }T \\newline \u0026amp; \\rbrace\\quad\\quad\\quad\\quad\\quad\\quad \\newline \u0026amp; \\newline \\texttt{NOT}(A) \u0026amp; \\texttt{If F}(AB)\\texttt{ Then}\\lbrace \\newline \\texttt{NOT}(B) \u0026amp; \\newline \\texttt{CCNOT}(ABT_1) \u0026amp; \\newline \\texttt{NOT}(A) \u0026amp; \\newline \\texttt{NOT}(B) \u0026amp; \\newline \\texttt{CNOT}(T_1A)\u0026amp; \\texttt{NOT}(A) \\newline \\texttt{CNOT}(T_1B)\u0026amp; \\texttt{NOT}(B) \\newline \u0026amp; \\rbrace\\quad\\quad\\quad\\quad\\quad\\quad\\quad \\newline \u0026amp; \\newline \\texttt{NOT}(C) \u0026amp; \\texttt{If F}(CD)\\texttt{ Then}\\lbrace \\newline \\texttt{NOT}(D) \u0026amp; \\newline \\texttt{CCNOT}(CDT_2) \u0026amp; \\newline \\texttt{NOT}(C) \u0026amp; \\newline \\texttt{NOT}(D) \u0026amp; \\newline \\texttt{CCNOT}(T_2CD)\u0026amp; \\texttt{CNOT}(CD) \\newline \u0026amp; \\rbrace\\quad\\quad\\quad\\quad\\quad\\quad\\quad \\newline \\end{array} $$\n","date":"2023-06-10T00:00:00Z","image":"https://kiblitz.github.io/p/quantum-computing-foundations/mountain_winter_hu5e08698192d656e72fd397b1c150bef5_3453251_120x120_fill_q75_box_smart1.jpeg","permalink":"https://kiblitz.github.io/p/quantum-computing-foundations/","title":"II. Quantum Computing Foundations"},{"content":"Sorting Lower Bound (Info Theory Argument) Theorem Any deterministic sorting algorithm on an array of length $n$ must make at least $\\log_2(n!)$ comparisons Proof Observe that sorting is just a permutation on the input array. In total, there are $n!$ permutations. In the worst case, only one permutation corresponds to a sorted array. This is when all elements in the array are unique\nObserve that each comparison ($a {_?\\atop \u0026gt;} b$) partitions the solution space into two: permutations that are still possibly correct and permutations that are not. Suppose we have $[3, 1, 2]$. At the start of the algorithm (without having made any comparisons), all permutations could potentially be correct (sorted). However, once we make the comparison between $3 {?\\atop \u0026gt;} 1 \\Rightarrow 1 \u0026lt; 3$, every permutation where $3$ comes before $1$ is known to be incorrect.\n$$\\cancel{[3,1,2]}\\newline\\cancel{[3,2,1]}\\newline[2,1,3]\\newline\\cancel{[2,3,1]}\\newline[1,3,2]\\newline[1,2,3]$$\nSince in the worst case, the algorithm will mark the smaller partition as incorrect, it must be the case that each comparison shrinks the solution space by at most half. So in the worst case, it takes $\\log_2(n!)$ comparisons. This is an information theoretic argument since the proof is explaining that any algorithm requires $\\log_2 n$ bits of information.\nUpper Bound $\\texttt{MergeSort}(A)$\nSplit $A$ into two contiguous subarrays $L,R$ with (approximately) equal number of elements $L\u0026rsquo;=\\texttt{MergeSort}(L)$, $R\u0026rsquo;=\\texttt{MergeSort}(R)$ Merge sorted $L\u0026rsquo;$ and $R\u0026rsquo;$ to create sorted $A\u0026rsquo;$ You can inductively reason that $L\u0026rsquo;$ and $R\u0026rsquo;$ are sorted.\nThe merging is done linearly using two pointers on $L\u0026rsquo;$ and $R\u0026rsquo;$ and appending the lesser of the two values to $A\u0026rsquo;$ while incrementing that pointer (this is possible because $L\u0026rsquo;$ and $R\u0026rsquo;$ are both sorted)\nThe only comparisons done in $\\texttt{MergeSort}$ are in the last step. Every comparison increments at least one pointer, which can happen at most $n-1$ times (See this for a more thorough explanation on the last step).\nUnrolling the recurrence: $$\\begin{align*}\u0026amp;\\thickspace\\underbrace{(n-1)+2(\\frac{n}{2}-1)+4(\\frac{n}{4}-1)+\u0026hellip;}_{\\log_2(n)}\\newline=\u0026amp;\\thickspace (n-1) + (n-2) + (n-4) + \u0026hellip; \\newline=\u0026amp;\\thickspace n\\log_2 n - (n - 1) \\newline \u0026lt;\u0026amp; \\thickspace n\\log_2 n\\newline\\in\u0026amp;\\thickspace \\mathcal{O}(n\\log n)\\end{align*}$$\nSince $\\log_2(n!)\\in\\Omega(n \\log n)$, the bound is tight. $$\\begin{align*}\\log_2 (n!) \u0026amp;= \\log_2(n) + \\log_2(n - 1) + \\log_2(n - 2) + \u0026hellip; + \\log_2(1) \\newline \u0026amp;\u0026gt; \\frac{n}{2}\\log_2 (\\frac{n}{2}) \\newline \u0026amp;= \\Omega(n \\log n) \\end{align*}$$\nMaximum Element Upper Bound Scanning the array from left to right while keeping track of the largest seen element requires $n-1$ comparisons.\nLower Bound Theorem Any deterministic maximum element algorithm must make at least $n - 1$ comparisons Proof AFSOC there exists an algorithm $\\mathcal{A}$ which makes less than $n-1$ comparisons. Construct a graph with $n$ vertices for each array element. For every comparison $\\mathcal{A}$ makes between two elements, append an edge to the graph between the corresponding vertices. Since there are less than $n-1$ edges, there must be at least two islands. If $\\mathcal{A}$ selects an element $e$ in an island, consider the same input array except all corresponding elements on every other island are incremented by $e$. The observations $\\mathcal{A}$ makes are the same since the comparisons known are only within an island, yet clearly $e$ cannot be the maximum element. Suppose our array is $[1, 2, 3, 4, 5, 6, 7]$ labelled $[a, b, c, d, e, f, g]$ and $\\mathcal{A}$ makes the following ($n-2=5$) comparisons: $$ a_{(1)}\u0026lt;c_{(3)}\\newline c_{(3)}\u0026lt;g_{(7)}\\newline g_{(7)}\u0026gt;d_{(4)}\\newline \\text{}\\newline b_{(2)}\u0026lt;f_{(6)}\\newline f_{(6)}\u0026gt;e_{(5)}\\newline $$\n1 2 3 4 5 6 7 = = = = = = = = = \u0026gt; 1 9 1 3 4 2 1 7 3 Now look at the comparisons after the incremental modification to $[1, 9, 3, 4, 5, 12, 13]$ labelled $[a, b, c, d, e, f, g]$: $$ a_{(1)}\u0026lt;c_{(3)}\\newline c_{(3)}\u0026lt;g_{(7)}\\newline g_{(7)}\u0026gt;d_{(4)}\\newline \\text{}\\newline b_{(9)}\u0026lt;f_{(13)}\\newline f_{(13)}\u0026gt;e_{(12)}\\newline $$ The comparisons are still true yet $\\mathcal{A}$\u0026rsquo;s original output is incorrect!\nSecond Largest Element Upper Bound Find the maximum element with a \u0026ldquo;playoffs\u0026rdquo; structure ($n-1$ comparisons).\n6 6 4 6 2 2 1 8 8 8 7 8 3 5 5 Observe that the second largest element is only less than the maximum element. Therefore, it must be the case that the second largest element had a comparison with the maximum element.\nSince there are $\\log_2 n$ \u0026ldquo;rounds\u0026rdquo;, it takes $\\log_2 n - 1$ comparisons to find the maximum element among those previously compared with the true maximum element.\nThus, this algorithm provides an upper bound of $n + \\log_2 n - 2$ comparisons.\nLower Bound (Adversarial Argument) Theorem Any deterministic second largest element algorithm must make at least $n + \\log_2 n - 2$ comparisons Proof Consider the set of all comparisons made that do not involve the maximum element. Since any algorithm $A$ finds the second largest element, the same argument from the previous problem can be made to prove that this set has at least $n-2$ elements. Let $M$ be the set of all comparisons made that involve the maximum element. The lower bound on the number of comparisons made by $A$ is\n$$n-2+|M|$$ We will now show that $|M|$ is at least $\\log_2 n$.\nLet each element have a corresponding weight associated with it. The weight $w$ represents the number of elements known to be less than it. Observe that with each comparison query $\\mathcal{A}$ makes between any two elements $e_1,e_2$, one of $w(e_1) := w(e_1) + w(e_2)$ or $w(e_2) := w(e_2) + w(e_1)$ will occur. Since either is possible before the comparison occurs, we can choose which is true upon $\\mathcal{A}$\u0026rsquo;s query. Specifically, we will minimize the weight increment (if $w(e_1) \u0026gt; w(e_2)$ then assign $e_1\u0026gt;e_2$ else assign $e_1\u0026lt;e_2$).\nObserve that with this dynamic response, any weight can at most double with each comparison. Since the algorithm only knows the maximum element once such an element obtains a weight of $n-1$ (there are $n-1$ elements less than the maximum one), $|M|\\geq \\log_2 n$.\n$$n - 2 + \\log_2 n$$\nThis is an adversarial argument since the proof constructs an adversary that dynamically responds to any algorithm\u0026rsquo;s queries such that it minimizes the algorithm\u0026rsquo;s effectiveness.\nGraph Connectivity Upper Bound Query every pair to know the entire graph. In an $n$-node graph, this is $n\\choose 2$ queries.\nLower Bound (Adversarial Argument) Theorem Any deterministic graph connectivity algorithm must make $n\\choose 2$ queries Proof We will again construct an adversary $\\mathcal{E}$ to maximize the number of required queries an algorithm $\\mathcal{A}$ must make. Observe that the edges declared by $\\mathcal{A}$ form a forest of trees (where $\\mathcal{A}$ aims to determine if the number of trees in the forest is exactly $1$). $\\mathcal{E}$ will maintain the following invariant.\nFor each tree $T$, all possible edges among its vertices have been queried For each pair of trees $T_1, T_2$, $\\exists (e_1,e_2)$ such that $e_1\\in T_1, e_2\\in T_2$. In other words, only dynamically create an edge if it is the last edge to connect two forests. Intuitively $\\mathcal{E}$\u0026rsquo;s idea is that if it creates an edge between two trees $T_1, T_2$, but it is not the last possible edge query between $T_1, T_2$, then $\\mathcal{A}$ would not need to query any more edges between $T_1, T_2$.\na T 1 b c ? T d e 2 In the above example, there currently exists $0$ queries between trees $T_1$ and $T_2$. If $\\mathcal{A}$ queries $(b, e)$ and $\\mathcal{E}$ responds with yes, then $\\mathcal{A}$ has no need to query any more edges between $T_1$ and $T_2$ because it already knows that there is going to be some path in $T_1$ to $b$ which connects to some path in $T_2$ to $e$.\nAFSOC $\\mathcal{A}$ outputs without querying $n\\choose 2$ edges from $\\mathcal{E}$. By definition of $\\mathcal{E}$, $\\exists T_1, T_2, \u0026hellip;, T_t$ such that there is no queried connecting edge between $T_i, T_j\\thickspace \\forall i, j$. If $\\mathcal{A}$ outputs yes, then suppose all un-queried edges are not in the graph. If $\\mathcal{A}$ outputs no, then suppose all un-queried edges are indeed in the graph. ","date":"2023-06-09T00:00:00Z","image":"https://kiblitz.github.io/p/bounding-problems/waterfall_rock_hu8ae446923e9393b75a0d2b39e2915362_11202311_120x120_fill_q75_box_smart1.jpg","permalink":"https://kiblitz.github.io/p/bounding-problems/","title":"II. Bounding Problems"},{"content":"Probabilistic Computing Analogy The first computing models were entirely deterministic. The idea of probabilistic computing brought about a single new instruction.\nc o i n f l i p 0 0 . . 5 5 It provided computers with greater functionality and the ability to solve problems in novel ways (randomized/approximation algorithms) as well as introduce a new space of problems not possible before (i.e. interactive proof systems).\nQuantum computing does something similar. Enter the Hadamard gate. Technically more but for now just the Hadamard gate\nHadamard The Hadamard gate is a modification operation on a single qubit. We will go over what a qubit is later. For now, it is sufficient to think of a qubit as a bit\nWhat does it do? Testing What happens if we execute the following? \u0026times; Refresh the page to see! $$\\texttt{INIT}(A)\\newline\\texttt{HAD}(A)$$ Seems like a coin flip. What about if $A=1$?\n$$\\texttt{INIT}(A)\\newline\\texttt{NOT}(A)\\newline\\texttt{HAD}(A)$$ Also a coin flip. Is quantum computing really just a computer that can coin flip?\nOk let\u0026rsquo;s see what happens when we chain $\\texttt{HAD}$ operations.\n$$\\texttt{INIT}(A)\\newline\\texttt{HAD}(A)\\newline\\texttt{HAD}(A)$$ $$\\texttt{INIT}(A)\\newline\\texttt{NOT}(A)\\newline\\texttt{HAD}(A)\\newline\\texttt{HAD}(A)$$ $$A=0$$ $$A=1$$ ???\nThe Qubit Before we can explain what\u0026rsquo;s going on, let\u0026rsquo;s revisit the qubit. It looks like a bit and acts like a bit with non-quantum instructions. But is it really a bit?\nIn reality, a qubit can be defined by a pair of amplitudes. Amplitudes in quantum computing are like what probabilities are in probabilistic computing. After a coin flip, the random bit has a $0.5$ probability of being $0$ and a $0.5$ probability of being $1$. The Hadamard gate has a similar effect except with the qubit\u0026rsquo;s amplitudes.\nQuantum pairs well with linear algebra. A qubit can be represented as a 2-dimensional vector where its components are the qubit\u0026rsquo;s amplitudes. In the example below, qubit $A$ has all of its amplitude on the $0$ state. $$A=\\begin{bmatrix}1 \\newline 0 \\end{bmatrix}$$In quantum, we typically use Bra-ket notation.$$A=1|0\\rangle + 0|1\\rangle = |0\\rangle$$\nSo how does a qubit resolve its amplitude state? A qubit with a non-trivial state is said to be in superposition. The probability that a qubit measures to a value is its amplitude on that value squared.\nSuppose $A=\\frac{\\sqrt{2}}{2}|0\\rangle + \\frac{\\sqrt{2}}{2}|1\\rangle$. Then, $A$ has a $0.5$ probability to measure with value $0$ and likewise $1$. Observe that the sum of the squares of amplitudes must sum to $1$. Because of this strict ratio property, we can represent qubits with their unnormalized state.$$A=|0\\rangle + |1\\rangle$$\nSo how does it offer any more than probabilistic computing?\nHadamard Definition In simple terms, the Hadamard gate has the following value mappings (amplitudes on arrows). $$\\begin{align*}0\u0026amp;\\xmapsto{\\frac{\\sqrt{2}}{2}}1\\newline0\u0026amp;\\xmapsto{\\frac{\\sqrt{2}}{2}}0\\end{align*}$$$$\\begin{align*}1\u0026amp;\\xmapsto{\\frac{\\sqrt{2}}{2}}0\\newline1\u0026amp;\\xmapsto{-\\frac{\\sqrt{2}}{2}}1\\newline\\end{align*}$$\nIt may be easier to think about the mappings in their unnormalized amplitudes$$\\begin{align*}0\u0026amp;\\xmapsto{1}1\\newline0\u0026amp;\\xmapsto{1}0\\end{align*}$$$$\\begin{align*}1\u0026amp;\\xmapsto{1}0\\newline1\u0026amp;\\xmapsto{-1}1\\newline\\end{align*}$$\nThe Hadamard gate can be represented by the following matrix.$$H=\\frac{\\sqrt{2}}{2}\\begin{bmatrix}1 \u0026amp; 1 \\newline 1 \u0026amp; -1\\end{bmatrix}$$\nRepresented as a pair of amplitude trees based on starting state:\n0 1 0 1 1 0 1 1 - 1 1 The root of the tree represents the starting state and the leaves the end state. The edges along any path represent the amplitudes (unnormalized in this example).\nThe interesting capability quantum offers over probabilistic computing is that qubits can have negative amplitudes.\nExamples $\\texttt{INIT}(A)\\newline\\texttt{HAD}(A)$\n0 1 0 1 1 $\\mathbb{P}[A=0]=0.5\\newline\\mathbb{P}[A=1]=0.5$\n$\\texttt{INIT}(A)\\newline\\texttt{NOT}(A)\\newline\\texttt{HAD}(A)$\n0 1 1 0 1 - 1 1 $\\mathbb{P}[A=0]=0.5\\newline\\mathbb{P}[A=1]=0.5$\nThis is consistent with our first two testing results where $\\texttt{HAD}$ acted like a coin flip.\n$\\texttt{INIT}(A)\\newline\\texttt{HAD}(A)\\newline\\texttt{HAD}(A)$\n0 1 0 1 1 1 0 0 1 1 1 - 1 1 $\\mathbb{A}[A=0]=1\\times 1 + 1\\times 1 = 2\\newline \\mathbb{A}[A=1]=1\\times 1 + 1\\times (-1) = 0$ Unnormalized\n$\\mathbb{P}[A=0]=1$\nOk, so this explains our last testing result. Essentially, there are two paths resulting in $A=1$ whose amplitudes cancelled each other out. This is the unique factor in quantum computing.\nThis is called destructive interference\nConcluding Remarks Quantum Computing Advantage Notice that the state of qubit $A$ only resolves at the end. If we were to only look at the right subtree, we would not know that an amplitude cancellation occured. In other words, to understand the behavior of a qubit we need knowledge on the entire amplitude tree. This is why simulating a quantum computer using a classical computer has exponential complexity.\nResolving Qubit Values At what point do the amplitude calculations resolve to probabilities? In other words, at what point is the value of $A$ known? In our examples, it seems to resolve at the end of the program. In actuality, a qubit is known when it is measured.\nIn our last example, if we had measured qubit $A$ at every step, then the value of $A$ at the end is equally $0$ or $1$ at every step (essentially just a series of coin flips).\n","date":"2023-06-07T00:00:00Z","image":"https://kiblitz.github.io/p/the-hadamard-gate/mountain_cross_hua7ba4afdc11e4243af2171792e272a69_2056581_120x120_fill_q75_box_smart1.jpeg","permalink":"https://kiblitz.github.io/p/the-hadamard-gate/","title":"I. The Hadamard Gate"},{"content":"Problem Find the $k$th smallest element in an unsorted array $A$ of size $n$.\nSorting has $\\mathcal{O}(n\\log n)$ time complexity and is overkill for this specific problem (solves for all $k$).\nQuickSelect Algorithm $\\texttt{QuickSelect}(A, k)$\nArbitrarily pick a pivot element $p$ from $A$ Split $A$ into $L = \\lbrace a | \\thickspace a \\in A \\text{ and } a \u0026lt; p \\rbrace$ and $G = \\lbrace a | \\thickspace a \\in A \\text{ and } a \u0026gt; p \\rbrace$ Recurse If $|L| = k$ then return $p$ If $|L| \u0026gt; k - 1$ then $\\texttt{QuickSelect}(L, k)$ If $|L| \u0026lt; k - 1$ then $\\texttt{QuickSelect}(G, k - (|L| + 1))$ The $A_k\\in G$ case has to readjust the recursive $k$ value since we are essentially throwing away the first $|L| + 1$ elements ($L$ and $p$).\nExample Suppose we always pick the first element $A_0$ to be $p$ (this is arbitrary for arbitrary $A$).\n$A$ can adversarially be monotonically ordered and the time complexity becomes $\\mathcal{O}(n^2)$\nk p k p k p r e = = = = = = t u 8 7 1 1 1 8 r , , , 1 , , n , L A L 8 L A = A = = = = = { } 5 8 , 8 7 1 G 1 1 1 = 1 0 5 0 8 4 1 9 0 1 9 1 6 2 , 9 4 G 3 1 0 = 6 2 9 1 3 2 , 1 1 G = 8 1 1 1 2 8 2 1 2 1 0 1 0 9 9 Analysis Theorem The expected number of comparisons is upper bounded by $4n$ Proof Let $C(A, n, k)$ be the cost (number of comparisons) to find the $k$th smallest element in an array $A$ of $n$ elements. Let $C(n) = \\max_{A,k} C(A,n,k)$. Convince yourself that $C(A,n,k)$ doesn\u0026rsquo;t depend on $A$\nIt takes $n - 1$ comparisons to split $A$ into $L$ and $G$. The sizes of the pieces take the same distribution as $p$, which is uniformly random. By our definition of $C$, we will always consider the larger of the two pieces in cost calculation. $$\\mathbb{E}[C(n)] \\leq (n-1) + \\text{avg}[C(\\frac{n}{2}),\u0026hellip;,C(n-1)]$$\nInductively, assume $\\mathbb{E}[C(i)] \\leq 4i$ for $i \u0026lt; n$ ($0$ comparisons when $n=1$ so the base case holds).\n$$\\begin{align*}\\mathbb{E}[C(n)] \u0026amp;\\leq (n-1) + \\text{avg}[4(\\frac{n}{2}),\u0026hellip;,4(n-1)] \\newline \u0026amp;\\leq (n-1) + 4(\\frac{3n}{4}) \\newline \u0026amp;\\leq 4n\\end{align*}$$ Technically we assumed $n$ is even, but the proof is basically the same in the odd case\nThus, QuickSelect has $\\mathcal{O}(n)$ time complexity.\nDeterministicSelect Algorithm Pick a parameter constant $\\alpha$. It matters what $\\alpha$ is, but for now suppose $\\alpha=5$\n$\\texttt{ApproxMedian}(A, \\alpha=5)$\nIf $|A| = 1$ then return $A_0$ Partition $A$ into groups $G_1, G_2, \u0026hellip; G_{\\frac{n}{\\alpha}}$ each of size $\\alpha$ Let $M = \\lbrace \\text{median}(G_i) \\forall i \\rbrace$ It doesn\u0026rsquo;t matter how median is calculated here since $\\alpha$ is constant implies each calculation has $\\mathcal{O}(1)$ time complexity ($\\mathcal{O}(n)$ total)\nreturn $\\texttt{DeterministicSelect}(M, \\lceil\\frac{|M|}{2}\\rceil)$ In other words, find the true median of the group medians\nThere are some integrality issues (that we will ignore) which complicate the analysis, though the time complexity should be unaffected\n$\\texttt{DeterministicSelect}(A, k)$\nIf $|A| \\leq \\alpha$ then return $k$th smallest value in $A$ by brute force Let the pivot $p$ be $\\texttt{ApproxMedian}(A)$ Split $A$ into $L = \\lbrace a | \\thickspace a \\in A \\text{ and } a \u0026lt; p \\rbrace$ and $G = \\lbrace a | \\thickspace a \\in A \\text{ and } a \u0026gt; p \\rbrace$ Recurse If $|L| = k$ then return $p$ If $|L| \u0026gt; k - 1$ then $\\texttt{DeterministicSelect}(L, k)$ If $|L| \u0026lt; k - 1$ then $\\texttt{DeterministicSelect}(G, k - (|L| + 1))$ Notice that the only difference between $\\texttt{QuickSelect}$ and $\\texttt{DeterministicSelect}$ is how the pivot $p$ is chosen\nApproxMedian Example $\\alpha=3$\nA M r e = 7 = t u r n 7 5 5 5 D k r e e 5 1 4 t = t e u r 2 r m , n 1 8 i n A 5 i 4 s = 4 1 t 4 i c 6 S 5 6 e 1 l 2 e 3 c 4 3 t 8 8 8 1 2 4 2 9 1 2 9 1 1 1 1 4 1 1 1 5 4 1 1 0 5 1 2 1 0 1 3 1 2 1 3 Analysis ApproxMedian Bound Lemma Let $p = \\texttt{ApproxMedian}(A)$. Let $n = \\lceil\\frac{n}{2\\alpha}\\rceil\\lceil\\frac{\\alpha}{2}\\rceil$. At least $n$ elements in $A$ are greater than $p$ and at least $n$ elements in $A$ are less than $p$. Proof WLOG look at the $\\leq$ case. By definition, $p$ is the true median of the group medians, so $\\lceil\\frac{n}{2\\alpha}\\rceil$ groups (including the group $p$ is in) have medians $\\leq p$. For each of those groups, there are $\\lceil\\frac{\\alpha}{2}\\rceil$ elements (including that group\u0026rsquo;s median) $\\leq$ that group\u0026rsquo;s median and therefore $p$.\nVisual\n7 7 3 4 6 3 4 5 5 1 5 6 1 1 2 8 7 1 5 7 4 9 4 6 1 1 1 0 2 3 6 3 2 8 9 1 1 1 1 4 5 3 8 2 8 1 1 1 0 2 3 9 2 1 1 9 1 1 1 1 4 1 4 5 1 1 1 5 1 1 4 0 1 1 5 2 1 3 1 0 1 2 1 3 $$\\texttt{ApproxMedian}(A)=8$$ $$\\begin{align}8 \u0026amp;\\geq 5\\geq 4 \\tag*{medians} \\newline 8\u0026amp;\\geq 2 \\tag*{group 3} \\newline 5\u0026amp;\\geq 1 \\tag*{group 2} \\newline 4\u0026amp;\\geq 3 \\tag*{group 1} \\newline 8\u0026amp;\\geq i \\thickspace \\forall i\\in\\lbrace 3, 4, 1, 5, 2, 8 \\rbrace \\tag*{$\\therefore$} \\end{align}$$\nTheorem If $\\alpha$ is chosen intelligently, $\\texttt{DeterministicSelect}$ makes $\\mathcal{O}(n)$ comparisons Proof Let $C(A, n, k)$ be the worst-case cost to find the $k$th smallest element in an array $A$ of $n$ elements and let $C(n) = \\max_{A,k} C(A,n,k)$. Finding the median of a single group has constant cost (since its size is bounded by $\\alpha$). Since there are a linear number of groups, this step has linear time complexity. As in $\\texttt{QuickSelect}$ it also take linear time to split $A$ into $L$ and $G$. The first recursive call to find the true median of medians has time complexity $C(\\frac{n}{\\alpha})$. Since there are that many number of medians\nThe second recursive call to search from a sub-piece has time complexity $C(n - \\lceil\\frac{n}{2\\alpha}\\rceil\\lceil\\frac{\\alpha}{2}\\rceil)$ by the ApproxMedian Bound Lemma. Since in worst case we recurse on the larger sub-piece\n$$C(n) \\leq \\gamma n + C(\\frac{n}{\\alpha}) + C(n - \\lceil\\frac{n}{2\\alpha}\\rceil\\lceil\\frac{\\alpha}{2}\\rceil)$$ $\\gamma$ is a constant where its subexpression represents linear time complexity from the first two bullet points\nUsing $\\alpha=5$ $$\\begin{align*}C(n)\u0026amp;\\leq \\gamma n + C(\\frac{n}{5}) + C(n - 3\\lceil\\frac{n}{10}\\rceil)\\newline\u0026amp;\\leq \\gamma n + C(\\frac{n}{5}) + C(\\frac{7n}{10})\\newline\u0026amp;\\leq \\gamma n[1 + (\\frac{1}{5} + \\frac{7}{10}) + (\\frac{1}{5}(\\frac{1}{5} + \\frac{7}{10}) + \\frac{7}{10}(\\frac{1}{5} + \\frac{7}{10})) + \u0026hellip; ] \\newline \u0026amp;\\leq \\gamma n[1 + (\\frac{9}{10}) + (\\frac{1}{5}\\cdot\\frac{9}{10} + \\frac{7}{10}\\cdot\\frac{9}{10}) + \u0026hellip;] \\newline \u0026amp;\\leq \\gamma n[1 + (\\frac{9}{10}) + (\\frac{9}{10})^2 + (\\frac{9}{10})^3 + \u0026hellip;] \\newline \u0026amp;\\leq 10\\gamma n \\newline \u0026amp;\\in \\mathcal{O}(n)\\end{align*}$$ Corollary $\\texttt{DeterministicSelect}$ has linear time complexity if $$\\begin{align*}\\frac{1}{\\alpha} + 1 - \\frac{1}{2\\alpha}\\lceil\\frac{\\alpha}{2}\\rceil \u0026amp;\u0026lt; 1\\newline\\frac{1}{\\alpha} - \\frac{1}{2\\alpha}\\lceil\\frac{\\alpha}{2}\\rceil \u0026amp;\u0026lt; 0\\end{align*}$$ ","date":"2023-06-04T00:00:00Z","image":"https://kiblitz.github.io/p/derandomization-kth-smallest-element/waterfall_fire_hu347de02130603f4e863b0f5d585fe51e_656683_120x120_fill_q75_box_smart1.jpg","permalink":"https://kiblitz.github.io/p/derandomization-kth-smallest-element/","title":"I. Derandomization: Kth Smallest Element"}]